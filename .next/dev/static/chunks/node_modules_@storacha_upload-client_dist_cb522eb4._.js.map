{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/service.js"],"sourcesContent":["import { connect } from '@ucanto/client';\nimport { CAR, HTTP } from '@ucanto/transport';\nimport * as DID from '@ipld/dag-ucan/did';\nexport const serviceURL = new URL('https://up.storacha.network');\nexport const servicePrincipal = DID.parse('did:web:up.storacha.network');\nexport const receiptsEndpoint = 'https://up.storacha.network/receipt/';\n/** @type {import('@ucanto/interface').ConnectionView<import('./types.js').Service>} */\nexport const connection = connect({\n    id: servicePrincipal,\n    codec: CAR.outbound,\n    channel: HTTP.open({\n        url: serviceURL,\n        method: 'POST',\n    }),\n});\n//# sourceMappingURL=service.js.map"],"names":[],"mappings":";;;;;;;;;;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;AACO,MAAM,aAAa,IAAI,IAAI;AAC3B,MAAM,mBAAmB,+JAAS,CAAC;AACnC,MAAM,mBAAmB;AAEzB,MAAM,aAAa,IAAA,qKAAO,EAAC;IAC9B,IAAI;IACJ,OAAO,4LAAG,CAAC,QAAQ;IACnB,SAAS,+LAAI,CAAC,IAAI,CAAC;QACf,KAAK;QACL,QAAQ;IACZ;AACJ,IACA,mCAAmC","ignoreList":[0]}},
    {"offset": {"line": 38, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/constants.js"],"sourcesContent":["export const REQUEST_RETRIES = 3;\n//# sourceMappingURL=constants.js.map"],"names":[],"mappings":";;;;AAAO,MAAM,kBAAkB,GAC/B,qCAAqC","ignoreList":[0]}},
    {"offset": {"line": 47, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/receipts.js"],"sourcesContent":["import retry, { AbortError } from 'p-retry';\nimport { CAR } from '@ucanto/transport';\nimport { isDelegation, Receipt } from '@ucanto/core';\nimport { receiptsEndpoint } from './service.js';\nimport { REQUEST_RETRIES } from './constants.js';\n/** @import * as API from './types.js' */\n/** @implements {API.ReceiptNotFound} */\nexport class ReceiptNotFound extends Error {\n    name = /** @type {const} */ ('ReceiptNotFound');\n    /**\n     * @param {API.UnknownLink} taskCid\n     */\n    constructor(taskCid) {\n        super();\n        this.taskCid = taskCid;\n    }\n    /* c8 ignore start */\n    get reason() {\n        return `receipt not found for task ${this.taskCid} in the indexed workflow`;\n    }\n}\n/** @implements {API.ReceiptMissing} */\nexport class ReceiptMissing extends Error {\n    name = /** @type {const} */ ('ReceiptMissing');\n    /**\n     * @param {API.UnknownLink} taskCid\n     */\n    constructor(taskCid) {\n        super();\n        this.taskCid = taskCid;\n    }\n    /* c8 ignore start */\n    get reason() {\n        return `receipt missing for task ${this.taskCid}`;\n    }\n}\n/**\n * Polls for a receipt for an executed task by its CID.\n *\n * @template {API.Capability} C\n * @template {Record<string, any>} S\n * @param {API.UCANLink<[C]>} taskCid\n * @param {API.ReceiptGetOptions<S> & API.Retryable} [options]\n * @returns {Promise<API.InferReceipt<C, S>>}\n */\nexport async function poll(taskCid, options) {\n    return await retry(async () => {\n        const res = await get(taskCid, options);\n        if (res.error) {\n            // @ts-ignore\n            if (res.error.name === 'ReceiptNotFound') {\n                // throw an error that will cause `p-retry` to retry with\n                throw res.error;\n            }\n            else {\n                throw new AbortError(new Error(`failed to fetch receipt for task: ${taskCid}`, {\n                    cause: res.error,\n                }));\n            }\n        }\n        return res.ok;\n    }, {\n        signal: options?.signal,\n        onFailedAttempt: console.warn,\n        /* c8 ignore next */\n        retries: options?.retries ?? REQUEST_RETRIES,\n    });\n}\n/**\n * Calculate a receipt endpoint from the URL of a channel, if it has one.\n *\n * @param {API.Channel<Record<string, any>>} channel\n */\nfunction receiptEndpointFromChannel(channel) {\n    if ('url' in channel && channel.url instanceof URL) {\n        const url = channel.url;\n        return new URL('/receipt/', url.toString());\n    }\n    else {\n        return null;\n    }\n}\n/**\n * Get a receipt for an executed task by its CID.\n *\n * @template {API.Capability} C\n * @template {Record<string, any>} S\n * @param {API.UCANLink<[C]>} taskCid\n * @param {API.ReceiptGetOptions<S>} [options]\n * @returns {Promise<API.Result<API.InferReceipt<C, S>, API.ReceiptNotFound|API.ReceiptMissing>>}\n */\nexport async function get(taskCid, options) {\n    const channel = options?.connection?.channel;\n    const endpoint = options?.endpoint ??\n        (channel && receiptEndpointFromChannel(channel)) ??\n        receiptsEndpoint;\n    // Fetch receipt from endpoint\n    const url = new URL(taskCid.toString(), endpoint);\n    const fetchReceipt = options?.fetch ?? globalThis.fetch.bind(globalThis);\n    const workflowResponse = await fetchReceipt(url, { signal: options?.signal });\n    /* c8 ignore start */\n    if (workflowResponse.status === 404) {\n        return {\n            error: new ReceiptNotFound(taskCid),\n        };\n    }\n    /* c8 ignore stop */\n    // Get receipt from Message Archive\n    const agentMessageBytes = new Uint8Array(await workflowResponse.arrayBuffer());\n    // Decode message\n    const agentMessage = await CAR.request.decode({\n        body: agentMessageBytes,\n        headers: {},\n    });\n    // Get receipt from the potential multiple receipts in the message\n    const receipt = \n    /** @type {API.InferReceipt<C, S>|undefined} */\n    (agentMessage.receipts.get(`${taskCid}`));\n    if (!receipt) {\n        // This could be an agent message containing an invocation for ucan/conclude\n        // that includes the receipt as an attached block, or it may contain a\n        // receipt for ucan/conclude that includes the receipt as an attached block.\n        const blocks = new Map();\n        for (const b of agentMessage.iterateIPLDBlocks()) {\n            blocks.set(b.cid.toString(), b);\n        }\n        const invocations = [...agentMessage.invocations];\n        for (const receipt of agentMessage.receipts.values()) {\n            if (isDelegation(receipt.ran)) {\n                invocations.push(receipt.ran);\n            }\n        }\n        for (const inv of invocations) {\n            /* c8 ignore next */\n            if (inv.capabilities[0]?.can !== 'ucan/conclude')\n                continue;\n            const root = Object(inv.capabilities[0].nb).receipt;\n            /* c8 ignore next 5 */\n            const receipt = root\n                ? /** @type {API.InferReceipt<C, S>|null} */ (Receipt.view({ root, blocks }, null))\n                : null;\n            /* c8 ignore next */\n            if (!receipt)\n                continue;\n            /* c8 ignore next */\n            const ran = isDelegation(receipt.ran) ? receipt.ran.cid : receipt.ran;\n            if (ran.toString() === taskCid.toString()) {\n                return { ok: receipt };\n            }\n        }\n        return {\n            error: new ReceiptMissing(taskCid),\n        };\n    }\n    return {\n        ok: receipt,\n    };\n}\n//# sourceMappingURL=receipts.js.map"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AACA;;;;;;AAGO,MAAM,wBAAwB;IACjC,OAA6B,kBAAmB;IAChD;;KAEC,GACD,YAAY,OAAO,CAAE;QACjB,KAAK;QACL,IAAI,CAAC,OAAO,GAAG;IACnB;IACA,mBAAmB,GACnB,IAAI,SAAS;QACT,OAAO,CAAC,2BAA2B,EAAE,IAAI,CAAC,OAAO,CAAC,wBAAwB,CAAC;IAC/E;AACJ;AAEO,MAAM,uBAAuB;IAChC,OAA6B,iBAAkB;IAC/C;;KAEC,GACD,YAAY,OAAO,CAAE;QACjB,KAAK;QACL,IAAI,CAAC,OAAO,GAAG;IACnB;IACA,mBAAmB,GACnB,IAAI,SAAS;QACT,OAAO,CAAC,yBAAyB,EAAE,IAAI,CAAC,OAAO,EAAE;IACrD;AACJ;AAUO,eAAe,KAAK,OAAO,EAAE,OAAO;IACvC,OAAO,MAAM,IAAA,iJAAK,EAAC;QACf,MAAM,MAAM,MAAM,IAAI,SAAS;QAC/B,IAAI,IAAI,KAAK,EAAE;YACX,aAAa;YACb,IAAI,IAAI,KAAK,CAAC,IAAI,KAAK,mBAAmB;gBACtC,yDAAyD;gBACzD,MAAM,IAAI,KAAK;YACnB,OACK;gBACD,MAAM,IAAI,oJAAU,CAAC,IAAI,MAAM,CAAC,kCAAkC,EAAE,SAAS,EAAE;oBAC3E,OAAO,IAAI,KAAK;gBACpB;YACJ;QACJ;QACA,OAAO,IAAI,EAAE;IACjB,GAAG;QACC,QAAQ,SAAS;QACjB,iBAAiB,QAAQ,IAAI;QAC7B,kBAAkB,GAClB,SAAS,SAAS,WAAW,yLAAe;IAChD;AACJ;AACA;;;;CAIC,GACD,SAAS,2BAA2B,OAAO;IACvC,IAAI,SAAS,WAAW,QAAQ,GAAG,YAAY,KAAK;QAChD,MAAM,MAAM,QAAQ,GAAG;QACvB,OAAO,IAAI,IAAI,aAAa,IAAI,QAAQ;IAC5C,OACK;QACD,OAAO;IACX;AACJ;AAUO,eAAe,IAAI,OAAO,EAAE,OAAO;IACtC,MAAM,UAAU,SAAS,YAAY;IACrC,MAAM,WAAW,SAAS,YACtB,CAAC,WAAW,2BAA2B,QAAQ,KAC/C,wLAAgB;IACpB,8BAA8B;IAC9B,MAAM,MAAM,IAAI,IAAI,QAAQ,QAAQ,IAAI;IACxC,MAAM,eAAe,SAAS,SAAS,WAAW,KAAK,CAAC,IAAI,CAAC;IAC7D,MAAM,mBAAmB,MAAM,aAAa,KAAK;QAAE,QAAQ,SAAS;IAAO;IAC3E,mBAAmB,GACnB,IAAI,iBAAiB,MAAM,KAAK,KAAK;QACjC,OAAO;YACH,OAAO,IAAI,gBAAgB;QAC/B;IACJ;IACA,kBAAkB,GAClB,mCAAmC;IACnC,MAAM,oBAAoB,IAAI,WAAW,MAAM,iBAAiB,WAAW;IAC3E,iBAAiB;IACjB,MAAM,eAAe,MAAM,4LAAG,CAAC,OAAO,CAAC,MAAM,CAAC;QAC1C,MAAM;QACN,SAAS,CAAC;IACd;IACA,kEAAkE;IAClE,MAAM,UAEL,aAAa,QAAQ,CAAC,GAAG,CAAC,GAAG,SAAS;IACvC,IAAI,CAAC,SAAS;QACV,4EAA4E;QAC5E,sEAAsE;QACtE,4EAA4E;QAC5E,MAAM,SAAS,IAAI;QACnB,KAAK,MAAM,KAAK,aAAa,iBAAiB,GAAI;YAC9C,OAAO,GAAG,CAAC,EAAE,GAAG,CAAC,QAAQ,IAAI;QACjC;QACA,MAAM,cAAc;eAAI,aAAa,WAAW;SAAC;QACjD,KAAK,MAAM,WAAW,aAAa,QAAQ,CAAC,MAAM,GAAI;YAClD,IAAI,IAAA,wKAAY,EAAC,QAAQ,GAAG,GAAG;gBAC3B,YAAY,IAAI,CAAC,QAAQ,GAAG;YAChC;QACJ;QACA,KAAK,MAAM,OAAO,YAAa;YAC3B,kBAAkB,GAClB,IAAI,IAAI,YAAY,CAAC,EAAE,EAAE,QAAQ,iBAC7B;YACJ,MAAM,OAAO,OAAO,IAAI,YAAY,CAAC,EAAE,CAAC,EAAE,EAAE,OAAO;YACnD,oBAAoB,GACpB,MAAM,UAAU,OACkC,mMAAO,CAAC,IAAI,CAAC;gBAAE;gBAAM;YAAO,GAAG,QAC3E;YACN,kBAAkB,GAClB,IAAI,CAAC,SACD;YACJ,kBAAkB,GAClB,MAAM,MAAM,IAAA,wKAAY,EAAC,QAAQ,GAAG,IAAI,QAAQ,GAAG,CAAC,GAAG,GAAG,QAAQ,GAAG;YACrE,IAAI,IAAI,QAAQ,OAAO,QAAQ,QAAQ,IAAI;gBACvC,OAAO;oBAAE,IAAI;gBAAQ;YACzB;QACJ;QACA,OAAO;YACH,OAAO,IAAI,eAAe;QAC9B;IACJ;IACA,OAAO;QACH,IAAI;IACR;AACJ,EACA,oCAAoC","ignoreList":[0]}},
    {"offset": {"line": 193, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/runtime.js"],"sourcesContent":["/* c8 ignore next 3 */\nexport const isCloudflareWorkers = typeof navigator !== 'undefined' &&\n    navigator?.userAgent === 'Cloudflare-Workers';\n//# sourceMappingURL=runtime.js.map"],"names":[],"mappings":"AAAA,oBAAoB;;;;AACb,MAAM,sBAAsB,OAAO,cAAc,eACpD,WAAW,cAAc,sBAC7B,mCAAmC","ignoreList":[0]}},
    {"offset": {"line": 202, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/add.js"],"sourcesContent":["import { ed25519 } from '@ucanto/principal';\nimport * as UCAN from '@storacha/capabilities/ucan';\nimport { Delegation, Receipt } from '@ucanto/core';\nimport * as BlobCapabilities from '@storacha/capabilities/blob';\nimport * as W3sBlobCapabilities from '@storacha/capabilities/web3.storage/blob';\nimport * as SpaceBlobCapabilities from '@storacha/capabilities/space/blob';\nimport * as HTTPCapabilities from '@storacha/capabilities/http';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport retry, { AbortError } from 'p-retry';\nimport { servicePrincipal, connection } from '../service.js';\nimport { REQUEST_RETRIES } from '../constants.js';\nimport { poll } from '../receipts.js';\nimport { isCloudflareWorkers } from '../runtime.js';\n/** @import * as API from '../types.js' */\n/**\n * @param {string} url\n * @param {API.ProgressFn} handler\n */\nfunction createUploadProgressHandler(url, handler) {\n    /** @param {API.ProgressStatus} status */\n    const onUploadProgress = ({ total, loaded, lengthComputable }) => {\n        return handler({ total, loaded, lengthComputable, url });\n    };\n    return onUploadProgress;\n}\n// FIXME this code has been copied over from upload-api\n/**\n * @param {API.Invocation} concludeFx\n */\nfunction getConcludeReceipt(concludeFx) {\n    const receiptBlocks = new Map();\n    for (const block of concludeFx.iterateIPLDBlocks()) {\n        receiptBlocks.set(`${block.cid}`, block);\n    }\n    return Receipt.view({\n        // @ts-expect-error object of type unknown\n        root: concludeFx.capabilities[0].nb.receipt,\n        blocks: receiptBlocks,\n    });\n}\n// FIXME this code has been copied over from upload-api\n/**\n * @param {API.Receipt} receipt\n */\nfunction parseBlobAddReceiptNext(receipt) {\n    // Get invocations next\n    /**\n     * @type {API.Invocation[]}\n     */\n    // @ts-expect-error read only effect\n    const forkInvocations = receipt.fx.fork;\n    const allocateTask = forkInvocations.find((fork) => fork.capabilities[0].can === BlobCapabilities.allocate.can\n    /* c8 ignore next 4 */ // tested by legacy integration test in w3up-client\n    ) ??\n        forkInvocations.find((fork) => fork.capabilities[0].can === W3sBlobCapabilities.allocate.can);\n    const concludefxs = forkInvocations.filter((fork) => fork.capabilities[0].can === UCAN.conclude.can);\n    const putTask = forkInvocations.find((fork) => fork.capabilities[0].can === HTTPCapabilities.put.can);\n    const acceptTask = \n    /** @type {API.Invocation<API.BlobAccept>|undefined} */\n    (forkInvocations.find((fork) => fork.capabilities[0].can === BlobCapabilities.accept.can\n    /* c8 ignore next 4 */ // tested by legacy integration test in w3up-client\n    ) ??\n        forkInvocations.find((fork) => fork.capabilities[0].can === W3sBlobCapabilities.accept.can));\n    /* c8 ignore next 3 */\n    if (!allocateTask || !concludefxs.length || !putTask || !acceptTask) {\n        throw new Error('mandatory effects not received');\n    }\n    // Decode receipts available\n    const nextReceipts = concludefxs.map((fx) => getConcludeReceipt(fx));\n    /** @type {API.Receipt<API.BlobAllocateSuccess, API.BlobAllocateFailure> | undefined} */\n    // @ts-expect-error types unknown for next\n    const allocateReceipt = nextReceipts.find((receipt) => receipt.ran.link().equals(allocateTask.cid));\n    /** @type {API.Receipt<{}, API.Failure> | undefined} */\n    // @ts-expect-error types unknown for next\n    const putReceipt = nextReceipts.find((receipt) => receipt.ran.link().equals(putTask.cid));\n    /** @type {API.Receipt<API.BlobAcceptSuccess, API.BlobAcceptFailure> | undefined} */\n    // @ts-expect-error types unknown for next\n    const acceptReceipt = nextReceipts.find((receipt) => receipt.ran.link().equals(acceptTask.cid));\n    /* c8 ignore next 3 */\n    if (!allocateReceipt) {\n        throw new Error('mandatory effects not received');\n    }\n    return {\n        allocate: {\n            task: allocateTask,\n            receipt: allocateReceipt,\n        },\n        put: {\n            task: putTask,\n            receipt: putReceipt,\n        },\n        accept: {\n            task: acceptTask,\n            receipt: acceptReceipt,\n        },\n    };\n}\n// FIXME this code has been copied over from upload-api\n/**\n * @param {API.Signer} id\n * @param {API.Principal} serviceDid\n * @param {API.Receipt} receipt\n */\nexport function createConcludeInvocation(id, serviceDid, receipt) {\n    const receiptBlocks = [];\n    const receiptCids = [];\n    for (const block of receipt.iterateIPLDBlocks()) {\n        receiptBlocks.push(block);\n        receiptCids.push(block.cid);\n    }\n    const concludeAllocatefx = UCAN.conclude.invoke({\n        issuer: id,\n        audience: serviceDid,\n        with: id.toDIDKey(),\n        nb: {\n            receipt: receipt.link(),\n        },\n        expiration: Infinity,\n        facts: [\n            {\n                ...receiptCids,\n            },\n        ],\n    });\n    for (const block of receiptBlocks) {\n        concludeAllocatefx.attach(block);\n    }\n    return concludeAllocatefx;\n}\n/**\n * Store a blob to the service. The issuer needs the `blob/add`\n * delegated capability.\n *\n * Required delegated capability proofs: `blob/add`\n *\n * @param {API.InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/add` delegated capability.\n * @param {import('multiformats').MultihashDigest} digest\n * @param {Blob|Uint8Array} data Blob data.\n * @param {API.RequestOptions} [options]\n * @returns {Promise<API.BlobAddOk>}\n */\nexport async function add({ issuer, with: resource, proofs, audience }, digest, data, options = {}) {\n    /* c8 ignore next 2 */\n    const bytes = data instanceof Uint8Array ? data : new Uint8Array(await data.arrayBuffer());\n    const size = bytes.length;\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await retry(async () => {\n        return await SpaceBlobCapabilities.add\n            .invoke({\n            issuer,\n            /* c8 ignore next */\n            audience: audience ?? servicePrincipal,\n            with: SpaceDID.from(resource),\n            nb: input(digest, size),\n            proofs,\n            nonce: options.nonce,\n        })\n            .execute(conn);\n    }, {\n        onFailedAttempt: console.warn,\n        retries: options.retries ?? REQUEST_RETRIES,\n    });\n    if (!result.out.ok) {\n        throw new Error(`failed ${SpaceBlobCapabilities.add.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    const nextTasks = parseBlobAddReceiptNext(result);\n    const { receipt: allocateReceipt } = nextTasks.allocate;\n    /* c8 ignore next 5 */\n    if (!allocateReceipt.out.ok) {\n        throw new Error(`failed ${SpaceBlobCapabilities.add.can} invocation`, {\n            cause: allocateReceipt.out.error,\n        });\n    }\n    const { address } = allocateReceipt.out.ok;\n    if (address) {\n        const fetchWithUploadProgress = options.fetchWithUploadProgress ||\n            options.fetch ||\n            globalThis.fetch.bind(globalThis);\n        let fetchDidCallUploadProgressCb = false;\n        await retry(async () => {\n            try {\n                const res = await fetchWithUploadProgress(address.url, {\n                    method: 'PUT',\n                    ...(!isCloudflareWorkers && { mode: 'cors' }),\n                    body: bytes,\n                    headers: address.headers,\n                    signal: options.signal,\n                    onUploadProgress: (status) => {\n                        fetchDidCallUploadProgressCb = true;\n                        if (options.onUploadProgress)\n                            createUploadProgressHandler(address.url, options.onUploadProgress)(status);\n                    },\n                    // @ts-expect-error - this is needed by recent versions of node - see https://github.com/bluesky-social/atproto/pull/470 for more info\n                    duplex: 'half',\n                });\n                // do not retry client errors\n                if (res.status >= 400 && res.status < 500) {\n                    throw new AbortError(`upload failed: ${res.status}`);\n                }\n                if (!res.ok) {\n                    throw new Error(`upload failed: ${res.status}`);\n                }\n                await res.arrayBuffer();\n            }\n            catch (err) {\n                if (options.signal?.aborted === true) {\n                    throw new AbortError('upload aborted');\n                }\n                throw err;\n            }\n        }, {\n            retries: options.retries ?? REQUEST_RETRIES,\n        });\n        if (!fetchDidCallUploadProgressCb && options.onUploadProgress) {\n            // the fetch implementation didn't support onUploadProgress\n            const blob = new Blob([bytes]);\n            options.onUploadProgress({\n                total: blob.size,\n                loaded: blob.size,\n                lengthComputable: false,\n            });\n        }\n    }\n    // Invoke `conclude` with `http/put` receipt\n    let { receipt: httpPutReceipt } = nextTasks.put;\n    if (!httpPutReceipt?.out.ok) {\n        const derivedSigner = ed25519.from(\n        /** @type {API.SignerArchive<API.DID, typeof ed25519.signatureCode>} */\n        (nextTasks.put.task.facts[0]['keys']));\n        httpPutReceipt = await Receipt.issue({\n            issuer: derivedSigner,\n            ran: nextTasks.put.task.cid,\n            result: { ok: {} },\n        });\n        const httpPutConcludeInvocation = createConcludeInvocation(issuer, \n        /* c8 ignore next */\n        audience ?? servicePrincipal, httpPutReceipt);\n        const ucanConclude = await httpPutConcludeInvocation.execute(conn);\n        if (!ucanConclude.out.ok) {\n            throw new Error(`failed ${UCAN.conclude.can} for ${HTTPCapabilities.put.can} invocation`, {\n                cause: ucanConclude.out.error,\n            });\n        }\n    }\n    // Ensure the blob has been accepted\n    let { receipt: acceptReceipt } = nextTasks.accept;\n    if (!acceptReceipt || !acceptReceipt.out.ok) {\n        acceptReceipt = await poll(nextTasks.accept.task.link(), {\n            ...options,\n            /* c8 ignore next 3 */\n            endpoint: options.receiptsEndpoint\n                ? new URL(options.receiptsEndpoint)\n                : undefined,\n            // The connection we have is for the upload service, which does not\n            // actually implement blob/accept. However, it does provide receipts for\n            // blob accept invocations it has made to storage nodes. Hence we type\n            // assert that this connection is a connecton to a service that\n            // implements blob/accept so that we can get a typed receipt back.\n            connection: /** @type {API.Connection<API.BlobService>} */ (Object(conn)),\n        });\n        /* c8 ignore next 5 */\n        if (acceptReceipt.out.error) {\n            throw new Error(`${BlobCapabilities.accept.can} failure`, {\n                cause: acceptReceipt.out.error,\n            });\n        }\n    }\n    const blocks = new Map([...acceptReceipt.iterateIPLDBlocks()].map((block) => [\n        `${block.cid}`,\n        block,\n    ]));\n    const site = Delegation.view({\n        root: /** @type {API.UCANLink<[import('@web3-storage/content-claims/capability/api').AssertLocation]>} */ (acceptReceipt.out.ok?.site),\n        blocks,\n    });\n    return { site };\n}\n/** Returns the ability used by an invocation. */\nexport const ability = SpaceBlobCapabilities.add.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats').MultihashDigest} digest\n * @param {number} size\n */\nexport const input = (digest, size) => ({\n    blob: {\n        digest: digest.bytes,\n        size,\n    },\n});\n//# sourceMappingURL=add.js.map"],"names":[],"mappings":";;;;;;;;;;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AACA,wCAAwC,GACxC;;;CAGC,GACD,SAAS,4BAA4B,GAAG,EAAE,OAAO;IAC7C,uCAAuC,GACvC,MAAM,mBAAmB,CAAC,EAAE,KAAK,EAAE,MAAM,EAAE,gBAAgB,EAAE;QACzD,OAAO,QAAQ;YAAE;YAAO;YAAQ;YAAkB;QAAI;IAC1D;IACA,OAAO;AACX;AACA,uDAAuD;AACvD;;CAEC,GACD,SAAS,mBAAmB,UAAU;IAClC,MAAM,gBAAgB,IAAI;IAC1B,KAAK,MAAM,SAAS,WAAW,iBAAiB,GAAI;QAChD,cAAc,GAAG,CAAC,GAAG,MAAM,GAAG,EAAE,EAAE;IACtC;IACA,OAAO,mMAAO,CAAC,IAAI,CAAC;QAChB,0CAA0C;QAC1C,MAAM,WAAW,YAAY,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO;QAC3C,QAAQ;IACZ;AACJ;AACA,uDAAuD;AACvD;;CAEC,GACD,SAAS,wBAAwB,OAAO;IACpC,uBAAuB;IACvB;;KAEC,GACD,oCAAoC;IACpC,MAAM,kBAAkB,QAAQ,EAAE,CAAC,IAAI;IACvC,MAAM,eAAe,gBAAgB,IAAI,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,kMAAyB,CAAC,GAAG,KAG1G,gBAAgB,IAAI,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,4MAA4B,CAAC,GAAG;IAChG,MAAM,cAAc,gBAAgB,MAAM,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,yKAAa,CAAC,GAAG;IACnG,MAAM,UAAU,gBAAgB,IAAI,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,oKAAoB,CAAC,GAAG;IACpG,MAAM,aAEL,gBAAgB,IAAI,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,gMAAuB,CAAC,GAAG,KAGpF,gBAAgB,IAAI,CAAC,CAAC,OAAS,KAAK,YAAY,CAAC,EAAE,CAAC,GAAG,KAAK,0MAA0B,CAAC,GAAG;IAC9F,oBAAoB,GACpB,IAAI,CAAC,gBAAgB,CAAC,YAAY,MAAM,IAAI,CAAC,WAAW,CAAC,YAAY;QACjE,MAAM,IAAI,MAAM;IACpB;IACA,4BAA4B;IAC5B,MAAM,eAAe,YAAY,GAAG,CAAC,CAAC,KAAO,mBAAmB;IAChE,sFAAsF,GACtF,0CAA0C;IAC1C,MAAM,kBAAkB,aAAa,IAAI,CAAC,CAAC,UAAY,QAAQ,GAAG,CAAC,IAAI,GAAG,MAAM,CAAC,aAAa,GAAG;IACjG,qDAAqD,GACrD,0CAA0C;IAC1C,MAAM,aAAa,aAAa,IAAI,CAAC,CAAC,UAAY,QAAQ,GAAG,CAAC,IAAI,GAAG,MAAM,CAAC,QAAQ,GAAG;IACvF,kFAAkF,GAClF,0CAA0C;IAC1C,MAAM,gBAAgB,aAAa,IAAI,CAAC,CAAC,UAAY,QAAQ,GAAG,CAAC,IAAI,GAAG,MAAM,CAAC,WAAW,GAAG;IAC7F,oBAAoB,GACpB,IAAI,CAAC,iBAAiB;QAClB,MAAM,IAAI,MAAM;IACpB;IACA,OAAO;QACH,UAAU;YACN,MAAM;YACN,SAAS;QACb;QACA,KAAK;YACD,MAAM;YACN,SAAS;QACb;QACA,QAAQ;YACJ,MAAM;YACN,SAAS;QACb;IACJ;AACJ;AAOO,SAAS,yBAAyB,EAAE,EAAE,UAAU,EAAE,OAAO;IAC5D,MAAM,gBAAgB,EAAE;IACxB,MAAM,cAAc,EAAE;IACtB,KAAK,MAAM,SAAS,QAAQ,iBAAiB,GAAI;QAC7C,cAAc,IAAI,CAAC;QACnB,YAAY,IAAI,CAAC,MAAM,GAAG;IAC9B;IACA,MAAM,qBAAqB,yKAAa,CAAC,MAAM,CAAC;QAC5C,QAAQ;QACR,UAAU;QACV,MAAM,GAAG,QAAQ;QACjB,IAAI;YACA,SAAS,QAAQ,IAAI;QACzB;QACA,YAAY;QACZ,OAAO;YACH;gBACI,GAAG,WAAW;YAClB;SACH;IACL;IACA,KAAK,MAAM,SAAS,cAAe;QAC/B,mBAAmB,MAAM,CAAC;IAC9B;IACA,OAAO;AACX;AAyBO,eAAe,IAAI,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,MAAM,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC;IAC9F,oBAAoB,GACpB,MAAM,QAAQ,gBAAgB,aAAa,OAAO,IAAI,WAAW,MAAM,KAAK,WAAW;IACvF,MAAM,OAAO,MAAM,MAAM;IACzB,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,IAAA,iJAAK,EAAC;QACvB,OAAO,MAAM,6LAAyB,CACjC,MAAM,CAAC;YACR;YACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;YACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;YACpB,IAAI,MAAM,QAAQ;YAClB;YACA,OAAO,QAAQ,KAAK;QACxB,GACK,OAAO,CAAC;IACjB,GAAG;QACC,iBAAiB,QAAQ,IAAI;QAC7B,SAAS,QAAQ,OAAO,IAAI,yLAAe;IAC/C;IACA,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,6LAAyB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAClE,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,MAAM,YAAY,wBAAwB;IAC1C,MAAM,EAAE,SAAS,eAAe,EAAE,GAAG,UAAU,QAAQ;IACvD,oBAAoB,GACpB,IAAI,CAAC,gBAAgB,GAAG,CAAC,EAAE,EAAE;QACzB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,6LAAyB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAClE,OAAO,gBAAgB,GAAG,CAAC,KAAK;QACpC;IACJ;IACA,MAAM,EAAE,OAAO,EAAE,GAAG,gBAAgB,GAAG,CAAC,EAAE;IAC1C,IAAI,SAAS;QACT,MAAM,0BAA0B,QAAQ,uBAAuB,IAC3D,QAAQ,KAAK,IACb,WAAW,KAAK,CAAC,IAAI,CAAC;QAC1B,IAAI,+BAA+B;QACnC,MAAM,IAAA,iJAAK,EAAC;YACR,IAAI;gBACA,MAAM,MAAM,MAAM,wBAAwB,QAAQ,GAAG,EAAE;oBACnD,QAAQ;oBACR,GAAI,CAAC,2LAAmB,IAAI;wBAAE,MAAM;oBAAO,CAAC;oBAC5C,MAAM;oBACN,SAAS,QAAQ,OAAO;oBACxB,QAAQ,QAAQ,MAAM;oBACtB,kBAAkB,CAAC;wBACf,+BAA+B;wBAC/B,IAAI,QAAQ,gBAAgB,EACxB,4BAA4B,QAAQ,GAAG,EAAE,QAAQ,gBAAgB,EAAE;oBAC3E;oBACA,sIAAsI;oBACtI,QAAQ;gBACZ;gBACA,6BAA6B;gBAC7B,IAAI,IAAI,MAAM,IAAI,OAAO,IAAI,MAAM,GAAG,KAAK;oBACvC,MAAM,IAAI,oJAAU,CAAC,CAAC,eAAe,EAAE,IAAI,MAAM,EAAE;gBACvD;gBACA,IAAI,CAAC,IAAI,EAAE,EAAE;oBACT,MAAM,IAAI,MAAM,CAAC,eAAe,EAAE,IAAI,MAAM,EAAE;gBAClD;gBACA,MAAM,IAAI,WAAW;YACzB,EACA,OAAO,KAAK;gBACR,IAAI,QAAQ,MAAM,EAAE,YAAY,MAAM;oBAClC,MAAM,IAAI,oJAAU,CAAC;gBACzB;gBACA,MAAM;YACV;QACJ,GAAG;YACC,SAAS,QAAQ,OAAO,IAAI,yLAAe;QAC/C;QACA,IAAI,CAAC,gCAAgC,QAAQ,gBAAgB,EAAE;YAC3D,2DAA2D;YAC3D,MAAM,OAAO,IAAI,KAAK;gBAAC;aAAM;YAC7B,QAAQ,gBAAgB,CAAC;gBACrB,OAAO,KAAK,IAAI;gBAChB,QAAQ,KAAK,IAAI;gBACjB,kBAAkB;YACtB;QACJ;IACJ;IACA,4CAA4C;IAC5C,IAAI,EAAE,SAAS,cAAc,EAAE,GAAG,UAAU,GAAG;IAC/C,IAAI,CAAC,gBAAgB,IAAI,IAAI;QACzB,MAAM,gBAAgB,wMAAO,CAAC,IAAI,CAEjC,UAAU,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC,OAAO;QACpC,iBAAiB,MAAM,mMAAO,CAAC,KAAK,CAAC;YACjC,QAAQ;YACR,KAAK,UAAU,GAAG,CAAC,IAAI,CAAC,GAAG;YAC3B,QAAQ;gBAAE,IAAI,CAAC;YAAE;QACrB;QACA,MAAM,4BAA4B,yBAAyB,QAC3D,kBAAkB,GAClB,YAAY,wLAAgB,EAAE;QAC9B,MAAM,eAAe,MAAM,0BAA0B,OAAO,CAAC;QAC7D,IAAI,CAAC,aAAa,GAAG,CAAC,EAAE,EAAE;YACtB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,yKAAa,CAAC,GAAG,CAAC,KAAK,EAAE,oKAAoB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;gBACtF,OAAO,aAAa,GAAG,CAAC,KAAK;YACjC;QACJ;IACJ;IACA,oCAAoC;IACpC,IAAI,EAAE,SAAS,aAAa,EAAE,GAAG,UAAU,MAAM;IACjD,IAAI,CAAC,iBAAiB,CAAC,cAAc,GAAG,CAAC,EAAE,EAAE;QACzC,gBAAgB,MAAM,IAAA,6KAAI,EAAC,UAAU,MAAM,CAAC,IAAI,CAAC,IAAI,IAAI;YACrD,GAAG,OAAO;YACV,oBAAoB,GACpB,UAAU,QAAQ,gBAAgB,GAC5B,IAAI,IAAI,QAAQ,gBAAgB,IAChC;YACN,mEAAmE;YACnE,wEAAwE;YACxE,sEAAsE;YACtE,+DAA+D;YAC/D,kEAAkE;YAClE,YAA4D,OAAO;QACvE;QACA,oBAAoB,GACpB,IAAI,cAAc,GAAG,CAAC,KAAK,EAAE;YACzB,MAAM,IAAI,MAAM,GAAG,gMAAuB,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE;gBACtD,OAAO,cAAc,GAAG,CAAC,KAAK;YAClC;QACJ;IACJ;IACA,MAAM,SAAS,IAAI,IAAI;WAAI,cAAc,iBAAiB;KAAG,CAAC,GAAG,CAAC,CAAC,QAAU;YACzE,GAAG,MAAM,GAAG,EAAE;YACd;SACH;IACD,MAAM,OAAO,4MAAU,CAAC,IAAI,CAAC;QACzB,MAA2G,cAAc,GAAG,CAAC,EAAE,EAAE;QACjI;IACJ;IACA,OAAO;QAAE;IAAK;AAClB;AAEO,MAAM,UAAU,6LAAyB,CAAC,GAAG;AAO7C,MAAM,QAAQ,CAAC,QAAQ,OAAS,CAAC;QACpC,MAAM;YACF,QAAQ,OAAO,KAAK;YACpB;QACJ;IACJ,CAAC,GACD,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 479, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/get.js"],"sourcesContent":["import * as BlobCapabilities from '@storacha/capabilities/space/blob';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * Gets a stored Blob file by digest.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/get/0/1` delegated capability.\n * @param {import('multiformats').MultihashDigest} multihash of the blob\n * @param {import('../types.js').RequestOptions} [options]\n */\nexport async function get({ issuer, with: resource, proofs, audience }, multihash, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await BlobCapabilities.get\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        nb: input(multihash),\n        proofs,\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!result.out.ok) {\n        throw new Error(`failed ${BlobCapabilities.get.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = BlobCapabilities.get.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats').MultihashDigest} digest\n */\nexport const input = (digest) => ({ digest: digest.bytes });\n//# sourceMappingURL=get.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAoBO,eAAe,IAAI,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;IAC3F,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,6LAAoB,CACpC,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB,IAAI,MAAM;QACV;QACA,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,6LAAoB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAC7D,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG;AACrB;AAEO,MAAM,UAAU,6LAAoB,CAAC,GAAG;AAMxC,MAAM,QAAQ,CAAC,SAAW,CAAC;QAAE,QAAQ,OAAO,KAAK;IAAC,CAAC,GAC1D,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 518, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/list.js"],"sourcesContent":["import * as BlobCapabilities from '@storacha/capabilities/space/blob';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * List Blobs stored in the space.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/list` delegated capability.\n * @param {import('../types.js').ListRequestOptions} [options]\n * @returns {Promise<import('../types.js').SpaceBlobListSuccess>}\n */\nexport async function list({ issuer, with: resource, proofs, audience }, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await BlobCapabilities.list\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        proofs,\n        nb: input(options.cursor, options.size),\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!result.out.ok) {\n        throw new Error(`failed ${BlobCapabilities.list.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = BlobCapabilities.list.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {string} [cursor]\n * @param {number} [size]\n */\nexport const input = (cursor, size) => ({ cursor, size });\n//# sourceMappingURL=list.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAoBO,eAAe,KAAK,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,UAAU,CAAC,CAAC;IACjF,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,8LAAqB,CACrC,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB;QACA,IAAI,MAAM,QAAQ,MAAM,EAAE,QAAQ,IAAI;QACtC,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,8LAAqB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAC9D,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,8LAAqB,CAAC,GAAG;AAOzC,MAAM,QAAQ,CAAC,QAAQ,OAAS,CAAC;QAAE;QAAQ;IAAK,CAAC,GACxD,gCAAgC","ignoreList":[0]}},
    {"offset": {"line": 558, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/remove.js"],"sourcesContent":["import * as BlobCapabilities from '@storacha/capabilities/space/blob';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * Remove a stored Blob file by digest.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/remove` delegated capability.\n * @param {import('multiformats').MultihashDigest} multihash of the blob\n * @param {import('../types.js').RequestOptions} [options]\n */\nexport async function remove({ issuer, with: resource, proofs, audience }, multihash, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await BlobCapabilities.remove\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        nb: input(multihash),\n        proofs,\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!result.out.ok) {\n        throw new Error(`failed ${BlobCapabilities.remove.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = BlobCapabilities.remove.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats').MultihashDigest} digest\n */\nexport const input = (digest) => ({ digest: digest.bytes });\n//# sourceMappingURL=remove.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAoBO,eAAe,OAAO,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;IAC9F,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,gMAAuB,CACvC,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB,IAAI,MAAM;QACV;QACA,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,gMAAuB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAChE,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG;AACrB;AAEO,MAAM,UAAU,gMAAuB,CAAC,GAAG;AAM3C,MAAM,QAAQ,CAAC,SAAW,CAAC;QAAE,QAAQ,OAAO,KAAK;IAAC,CAAC,GAC1D,kCAAkC","ignoreList":[0]}},
    {"offset": {"line": 597, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/replicate.js"],"sourcesContent":["import * as BlobCapabilities from '@storacha/capabilities/space/blob';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * @import { MultihashDigest } from 'multiformats'\n * @import { Delegation } from '@ucanto/interface'\n * @import { AssertLocation } from '@web3-storage/content-claims/capability/api'\n */\n/**\n * Replicate a stored Blob by digest to the specified number of nodes.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `space/blob/replicate` delegated capability.\n * @param {object} blob Details of the blob to replicate.\n * @param {MultihashDigest} blob.digest Hash of the blob.\n * @param {number} blob.size Total size of the blob in bytes.\n * @param {Delegation<[AssertLocation]>} site Location commitment describing\n * where the blob may be retrieved.\n * @param {number} replicas Total number of replicas to provision.\n * @param {import('../types.js').RequestOptions} [options]\n */\nexport async function replicate({ issuer, with: resource, proofs, audience }, blob, site, replicas, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const receipt = await BlobCapabilities.replicate\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        nb: input(blob, site, replicas),\n        proofs: [...proofs, site],\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!receipt.out.ok) {\n        throw new Error(`failed ${BlobCapabilities.replicate.can} invocation`, {\n            cause: receipt.out.error,\n        });\n    }\n    return receipt.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = BlobCapabilities.replicate.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {object} blob Details of the blob to replicate.\n * @param {MultihashDigest} blob.digest Hash of the blob.\n * @param {number} blob.size Total size of the blob in bytes.\n * @param {Delegation<[AssertLocation]>} site Location commitment describing\n * where the blob may be retrieved.\n * @param {number} replicas Total number of replicas to provision.\n */\nexport const input = (blob, site, replicas) => ({\n    blob: {\n        digest: blob.digest.bytes,\n        size: blob.size,\n    },\n    site: site.cid,\n    replicas,\n});\n//# sourceMappingURL=replicate.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AA8BO,eAAe,UAAU,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,IAAI,EAAE,IAAI,EAAE,QAAQ,EAAE,UAAU,CAAC,CAAC;IAC5G,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,UAAU,MAAM,mMAA0B,CAC3C,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB,IAAI,MAAM,MAAM,MAAM;QACtB,QAAQ;eAAI;YAAQ;SAAK;QACzB,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,QAAQ,GAAG,CAAC,EAAE,EAAE;QACjB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,mMAA0B,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YACnE,OAAO,QAAQ,GAAG,CAAC,KAAK;QAC5B;IACJ;IACA,OAAO,QAAQ,GAAG,CAAC,EAAE;AACzB;AAEO,MAAM,UAAU,mMAA0B,CAAC,GAAG;AAW9C,MAAM,QAAQ,CAAC,MAAM,MAAM,WAAa,CAAC;QAC5C,MAAM;YACF,QAAQ,KAAK,MAAM,CAAC,KAAK;YACzB,MAAM,KAAK,IAAI;QACnB;QACA,MAAM,KAAK,GAAG;QACd;IACJ,CAAC,GACD,qCAAqC","ignoreList":[0]}},
    {"offset": {"line": 644, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/blob/index.js"],"sourcesContent":["export { add } from './add.js';\nexport { get } from './get.js';\nexport { list } from './list.js';\nexport { remove } from './remove.js';\nexport { replicate } from './replicate.js';\n//# sourceMappingURL=index.js.map"],"names":[],"mappings":";AAAA;AACA;AACA;AACA;AACA,iTACA,iCAAiC","ignoreList":[0]}},
    {"offset": {"line": 681, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/index/add.js"],"sourcesContent":["import * as IndexCapabilities from '@storacha/capabilities/space/index';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport retry from 'p-retry';\nimport { servicePrincipal, connection } from '../service.js';\nimport { REQUEST_RETRIES } from '../constants.js';\n/**\n * Register an \"index\" with the service. The issuer needs the `index/add`\n * delegated capability.\n *\n * Required delegated capability proofs: `index/add`\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `index/add` delegated capability.\n * @param {import('../types.js').CARLink} index Index to store.\n * @param {import('../types.js').RequestOptions} [options]\n * @returns {Promise<import('../types.js').SpaceIndexAddSuccess>}\n */\nexport async function add({ issuer, with: resource, proofs, audience }, index, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await retry(async () => {\n        return await IndexCapabilities.add\n            .invoke({\n            issuer,\n            /* c8 ignore next */\n            audience: audience ?? servicePrincipal,\n            with: SpaceDID.from(resource),\n            nb: input(index),\n            proofs,\n        })\n            .execute(conn);\n    }, {\n        onFailedAttempt: console.warn,\n        retries: options.retries ?? REQUEST_RETRIES,\n    });\n    if (!result.out.ok) {\n        throw new Error(`failed ${IndexCapabilities.add.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = IndexCapabilities.add.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('../types.js').CARLink} index\n */\nexport const input = (index) => ({ index });\n//# sourceMappingURL=add.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;AACA;;;;;;AAwBO,eAAe,IAAI,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,KAAK,EAAE,UAAU,CAAC,CAAC;IACvF,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,IAAA,iJAAK,EAAC;QACvB,OAAO,MAAM,8LAAqB,CAC7B,MAAM,CAAC;YACR;YACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;YACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;YACpB,IAAI,MAAM;YACV;QACJ,GACK,OAAO,CAAC;IACjB,GAAG;QACC,iBAAiB,QAAQ,IAAI;QAC7B,SAAS,QAAQ,OAAO,IAAI,yLAAe;IAC/C;IACA,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,8LAAqB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAC9D,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,8LAAqB,CAAC,GAAG;AAMzC,MAAM,QAAQ,CAAC,QAAU,CAAC;QAAE;IAAM,CAAC,GAC1C,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 728, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/index/index.js"],"sourcesContent":["export { add } from './add.js';\n//# sourceMappingURL=index.js.map"],"names":[],"mappings":";AAAA,uSACA,iCAAiC","ignoreList":[0]}},
    {"offset": {"line": 745, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/upload/add.js"],"sourcesContent":["import * as UploadCapabilities from '@storacha/capabilities/upload';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport retry from 'p-retry';\nimport { servicePrincipal, connection } from '../service.js';\nimport { REQUEST_RETRIES } from '../constants.js';\n/**\n * Register an \"upload\" with the service. The issuer needs the `upload/add`\n * delegated capability.\n *\n * Required delegated capability proofs: `upload/add`\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `upload/add` delegated capability.\n * @param {import('multiformats/link').UnknownLink} root Root data CID for the DAG that was stored.\n * @param {import('../types.js').CARLink[]} shards CIDs of CAR files that contain the DAG.\n * @param {import('../types.js').RequestOptions} [options]\n * @returns {Promise<import('../types.js').UploadAddSuccess>}\n */\nexport async function add({ issuer, with: resource, proofs, audience }, root, shards, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await retry(async () => {\n        return await UploadCapabilities.add\n            .invoke({\n            issuer,\n            /* c8 ignore next */\n            audience: audience ?? servicePrincipal,\n            with: SpaceDID.from(resource),\n            nb: input(root, shards),\n            proofs,\n            nonce: options.nonce,\n        })\n            .execute(conn);\n    }, {\n        onFailedAttempt: console.warn,\n        retries: options.retries ?? REQUEST_RETRIES,\n    });\n    if (!result.out.ok) {\n        throw new Error(`failed ${UploadCapabilities.add.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = UploadCapabilities.add.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats/link').UnknownLink} root\n * @param {import('../types.js').CARLink[]} shards\n */\nexport const input = (root, shards) => ({ root, shards });\n//# sourceMappingURL=add.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;AACA;;;;;;AAyBO,eAAe,IAAI,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,IAAI,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;IAC9F,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,IAAA,iJAAK,EAAC;QACvB,OAAO,MAAM,sLAAsB,CAC9B,MAAM,CAAC;YACR;YACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;YACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;YACpB,IAAI,MAAM,MAAM;YAChB;YACA,OAAO,QAAQ,KAAK;QACxB,GACK,OAAO,CAAC;IACjB,GAAG;QACC,iBAAiB,QAAQ,IAAI;QAC7B,SAAS,QAAQ,OAAO,IAAI,yLAAe;IAC/C;IACA,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,sLAAsB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAC/D,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,sLAAsB,CAAC,GAAG;AAO1C,MAAM,QAAQ,CAAC,MAAM,SAAW,CAAC;QAAE;QAAM;IAAO,CAAC,GACxD,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 794, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/upload/get.js"],"sourcesContent":["import * as UploadCapabilities from '@storacha/capabilities/upload';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport retry from 'p-retry';\nimport { servicePrincipal, connection } from '../service.js';\nimport { REQUEST_RETRIES } from '../constants.js';\n/**\n * Get details of an \"upload\".\n *\n * Required delegated capability proofs: `upload/get`\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `upload/get` delegated capability.\n * @param {import('multiformats/link').UnknownLink} root Root data CID for the DAG that was stored.\n * @param {import('../types.js').RequestOptions} [options]\n * @returns {Promise<import('../types.js').UploadGetSuccess>}\n */\nexport async function get({ issuer, with: resource, proofs, audience }, root, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await retry(async () => {\n        return await UploadCapabilities.get\n            .invoke({\n            issuer,\n            /* c8 ignore next */\n            audience: audience ?? servicePrincipal,\n            with: SpaceDID.from(resource),\n            nb: input(root),\n            proofs,\n            nonce: options.nonce,\n        })\n            .execute(conn);\n    }, {\n        onFailedAttempt: console.warn,\n        retries: options.retries ?? REQUEST_RETRIES,\n    });\n    if (!result.out.ok) {\n        throw new Error(`failed ${UploadCapabilities.get.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = UploadCapabilities.get.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats/link').UnknownLink} root\n */\nexport const input = (root) => ({ root });\n//# sourceMappingURL=get.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;AACA;;;;;;AAuBO,eAAe,IAAI,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC;IACtF,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,IAAA,iJAAK,EAAC;QACvB,OAAO,MAAM,sLAAsB,CAC9B,MAAM,CAAC;YACR;YACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;YACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;YACpB,IAAI,MAAM;YACV;YACA,OAAO,QAAQ,KAAK;QACxB,GACK,OAAO,CAAC;IACjB,GAAG;QACC,iBAAiB,QAAQ,IAAI;QAC7B,SAAS,QAAQ,OAAO,IAAI,yLAAe;IAC/C;IACA,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,sLAAsB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAC/D,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,sLAAsB,CAAC,GAAG;AAM1C,MAAM,QAAQ,CAAC,OAAS,CAAC;QAAE;IAAK,CAAC,GACxC,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 842, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/upload/list.js"],"sourcesContent":["import * as UploadCapabilities from '@storacha/capabilities/upload';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * List uploads created by the issuer.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `upload/list` delegated capability.\n * @param {import('../types.js').ListRequestOptions} [options]\n * @returns {Promise<import('../types.js').UploadListSuccess>}\n */\nexport async function list({ issuer, with: resource, proofs, audience }, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await UploadCapabilities.list\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        proofs,\n        nb: input(options.cursor, options.size, options.pre),\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!result.out.ok) {\n        throw new Error(`failed ${UploadCapabilities.list.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = UploadCapabilities.list.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {string} [cursor]\n * @param {number} [size]\n * @param {boolean} [pre]\n */\nexport const input = (cursor, size, pre) => ({ cursor, size, pre });\n//# sourceMappingURL=list.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAoBO,eAAe,KAAK,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,UAAU,CAAC,CAAC;IACjF,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,uLAAuB,CACvC,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB;QACA,IAAI,MAAM,QAAQ,MAAM,EAAE,QAAQ,IAAI,EAAE,QAAQ,GAAG;QACnD,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,uLAAuB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAChE,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,uLAAuB,CAAC,GAAG;AAQ3C,MAAM,QAAQ,CAAC,QAAQ,MAAM,MAAQ,CAAC;QAAE;QAAQ;QAAM;IAAI,CAAC,GAClE,gCAAgC","ignoreList":[0]}},
    {"offset": {"line": 883, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/upload/remove.js"],"sourcesContent":["import * as UploadCapabilities from '@storacha/capabilities/upload';\nimport { SpaceDID } from '@storacha/capabilities/utils';\nimport { servicePrincipal, connection } from '../service.js';\n/**\n * Remove an upload by root data CID.\n *\n * @param {import('../types.js').InvocationConfig} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `upload/remove` delegated capability.\n * @param {import('multiformats').UnknownLink} root Root data CID to remove.\n * @param {import('../types.js').RequestOptions} [options]\n */\nexport async function remove({ issuer, with: resource, proofs, audience }, root, options = {}) {\n    /* c8 ignore next */\n    const conn = options.connection ?? connection;\n    const result = await UploadCapabilities.remove\n        .invoke({\n        issuer,\n        /* c8 ignore next */\n        audience: audience ?? servicePrincipal,\n        with: SpaceDID.from(resource),\n        nb: input(root),\n        proofs,\n        nonce: options.nonce,\n    })\n        .execute(conn);\n    if (!result.out.ok) {\n        throw new Error(`failed ${UploadCapabilities.remove.can} invocation`, {\n            cause: result.out.error,\n        });\n    }\n    return result.out.ok;\n}\n/** Returns the ability used by an invocation. */\nexport const ability = UploadCapabilities.remove.can;\n/**\n * Returns required input to the invocation.\n *\n * @param {import('multiformats').UnknownLink} root\n */\nexport const input = (root) => ({ root });\n//# sourceMappingURL=remove.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAoBO,eAAe,OAAO,EAAE,MAAM,EAAE,MAAM,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC;IACzF,kBAAkB,GAClB,MAAM,OAAO,QAAQ,UAAU,IAAI,kLAAU;IAC7C,MAAM,SAAS,MAAM,yLAAyB,CACzC,MAAM,CAAC;QACR;QACA,kBAAkB,GAClB,UAAU,YAAY,wLAAgB;QACtC,MAAM,0KAAQ,CAAC,IAAI,CAAC;QACpB,IAAI,MAAM;QACV;QACA,OAAO,QAAQ,KAAK;IACxB,GACK,OAAO,CAAC;IACb,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,yLAAyB,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;YAClE,OAAO,OAAO,GAAG,CAAC,KAAK;QAC3B;IACJ;IACA,OAAO,OAAO,GAAG,CAAC,EAAE;AACxB;AAEO,MAAM,UAAU,yLAAyB,CAAC,GAAG;AAM7C,MAAM,QAAQ,CAAC,OAAS,CAAC;QAAE;IAAK,CAAC,GACxC,kCAAkC","ignoreList":[0]}},
    {"offset": {"line": 922, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/upload/index.js"],"sourcesContent":["export { add } from './add.js';\nexport { get } from './get.js';\nexport { list } from './list.js';\nexport { remove } from './remove.js';\n//# sourceMappingURL=index.js.map"],"names":[],"mappings":";AAAA;AACA;AACA;AACA,+SACA,iCAAiC","ignoreList":[0]}},
    {"offset": {"line": 954, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/unixfs.js"],"sourcesContent":["import * as UnixFS from '@ipld/unixfs';\nimport * as raw from 'multiformats/codecs/raw';\nimport { withMaxChunkSize } from '@ipld/unixfs/file/chunker/fixed';\nimport { withWidth } from '@ipld/unixfs/file/layout/balanced';\nconst SHARD_THRESHOLD = 1000; // shard directory after > 1,000 items\nconst queuingStrategy = UnixFS.withCapacity();\nconst defaultSettings = UnixFS.configure({\n    fileChunkEncoder: raw,\n    smallFileEncoder: raw,\n    chunker: withMaxChunkSize(1024 * 1024),\n    fileLayout: withWidth(1024),\n});\n/**\n * @param {import('./types.js').BlobLike} blob\n * @param {import('./types.js').UnixFSEncoderSettingsOptions} [options]\n * @returns {Promise<import('./types.js').UnixFSEncodeResult>}\n */\nexport async function encodeFile(blob, options) {\n    const readable = createFileEncoderStream(blob, options);\n    const blocks = await collect(readable);\n    // @ts-expect-error There is always a root block\n    return { cid: blocks.at(-1).cid, blocks };\n}\n/**\n * @param {import('./types.js').BlobLike} blob\n * @param {import('./types.js').UnixFSEncoderSettingsOptions} [options]\n * @returns {ReadableStream<import('@ipld/unixfs').Block>}\n */\nexport function createFileEncoderStream(blob, options) {\n    /** @type {TransformStream<import('@ipld/unixfs').Block, import('@ipld/unixfs').Block>} */\n    const { readable, writable } = new TransformStream({}, queuingStrategy);\n    const settings = options?.settings ?? defaultSettings;\n    const unixfsWriter = UnixFS.createWriter({ writable, settings });\n    const fileBuilder = new UnixFSFileBuilder('', blob);\n    void (async () => {\n        await fileBuilder.finalize(unixfsWriter);\n        await unixfsWriter.close();\n    })();\n    return readable;\n}\nclass UnixFSFileBuilder {\n    #file;\n    /**\n     * @param {string} name\n     * @param {import('./types.js').BlobLike} file\n     */\n    constructor(name, file) {\n        this.name = name;\n        this.#file = file;\n    }\n    /** @param {import('@ipld/unixfs').View} writer */\n    async finalize(writer) {\n        const unixfsFileWriter = UnixFS.createFileWriter(writer);\n        await this.#file.stream().pipeTo(new WritableStream({\n            async write(chunk) {\n                await unixfsFileWriter.write(chunk);\n            },\n        }));\n        return await unixfsFileWriter.close();\n    }\n}\nclass UnixFSDirectoryBuilder {\n    #options;\n    /** @type {Map<string, UnixFSFileBuilder | UnixFSDirectoryBuilder>} */\n    entries = new Map();\n    /**\n     * @param {string} name\n     * @param {import('./types.js').UnixFSDirectoryEncoderOptions} [options]\n     */\n    constructor(name, options) {\n        this.name = name;\n        this.#options = options;\n    }\n    /** @param {import('@ipld/unixfs').View} writer */\n    async finalize(writer) {\n        const dirWriter = this.entries.size <= SHARD_THRESHOLD\n            ? UnixFS.createDirectoryWriter(writer)\n            : UnixFS.createShardedDirectoryWriter(writer);\n        for (const [name, entry] of this.entries) {\n            const link = await entry.finalize(writer);\n            if (this.#options?.onDirectoryEntryLink) {\n                // @ts-expect-error\n                this.#options.onDirectoryEntryLink({ name: entry.name, ...link });\n            }\n            dirWriter.set(name, link);\n        }\n        return await dirWriter.close();\n    }\n}\n/**\n * @param {Iterable<import('./types.js').FileLike>} files\n * @param {import('./types.js').UnixFSEncoderSettingsOptions & import('./types.js').UnixFSDirectoryEncoderOptions} [options]\n * @returns {Promise<import('./types.js').UnixFSEncodeResult>}\n */\nexport async function encodeDirectory(files, options) {\n    const readable = createDirectoryEncoderStream(files, options);\n    const blocks = await collect(readable);\n    // @ts-expect-error There is always a root block\n    return { cid: blocks.at(-1).cid, blocks };\n}\n/**\n * @param {Iterable<import('./types.js').FileLike>} files\n * @param {import('./types.js').UnixFSEncoderSettingsOptions & import('./types.js').UnixFSDirectoryEncoderOptions} [options]\n * @returns {ReadableStream<import('@ipld/unixfs').Block>}\n */\nexport function createDirectoryEncoderStream(files, options) {\n    const rootDir = new UnixFSDirectoryBuilder('', options);\n    for (const file of files) {\n        const path = file.name.split('/');\n        if (path[0] === '' || path[0] === '.') {\n            path.shift();\n        }\n        let dir = rootDir;\n        for (const [i, name] of path.entries()) {\n            if (i === path.length - 1) {\n                dir.entries.set(name, new UnixFSFileBuilder(path.join('/'), file));\n                break;\n            }\n            let dirBuilder = dir.entries.get(name);\n            if (dirBuilder == null) {\n                const dirName = dir === rootDir ? name : `${dir.name}/${name}`;\n                dirBuilder = new UnixFSDirectoryBuilder(dirName, options);\n                dir.entries.set(name, dirBuilder);\n            }\n            if (!(dirBuilder instanceof UnixFSDirectoryBuilder)) {\n                throw new Error(`\"${file.name}\" cannot be a file and a directory`);\n            }\n            dir = dirBuilder;\n        }\n    }\n    /** @type {TransformStream<import('@ipld/unixfs').Block, import('@ipld/unixfs').Block>} */\n    const { readable, writable } = new TransformStream({}, queuingStrategy);\n    const settings = options?.settings ?? defaultSettings;\n    const unixfsWriter = UnixFS.createWriter({ writable, settings });\n    void (async () => {\n        const link = await rootDir.finalize(unixfsWriter);\n        if (options?.onDirectoryEntryLink) {\n            options.onDirectoryEntryLink({ name: '', ...link });\n        }\n        await unixfsWriter.close();\n    })();\n    return readable;\n}\n/**\n * @template T\n * @param {ReadableStream<T>} collectable\n * @returns {Promise<T[]>}\n */\nasync function collect(collectable) {\n    /** @type {T[]} */\n    const chunks = [];\n    await collectable.pipeTo(new WritableStream({\n        write(chunk) {\n            chunks.push(chunk);\n        },\n    }));\n    return chunks;\n}\n//# sourceMappingURL=unixfs.js.map"],"names":[],"mappings":";;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;;;;AACA,MAAM,kBAAkB,MAAM,sCAAsC;AACpE,MAAM,kBAAkB,iLAAmB;AAC3C,MAAM,kBAAkB,+KAAgB,CAAC;IACrC,kBAAkB;IAClB,kBAAkB;IAClB,SAAS,IAAA,0LAAgB,EAAC,OAAO;IACjC,YAAY,IAAA,qLAAS,EAAC;AAC1B;AAMO,eAAe,WAAW,IAAI,EAAE,OAAO;IAC1C,MAAM,WAAW,wBAAwB,MAAM;IAC/C,MAAM,SAAS,MAAM,QAAQ;IAC7B,gDAAgD;IAChD,OAAO;QAAE,KAAK,OAAO,EAAE,CAAC,CAAC,GAAG,GAAG;QAAE;IAAO;AAC5C;AAMO,SAAS,wBAAwB,IAAI,EAAE,OAAO;IACjD,wFAAwF,GACxF,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,GAAG,IAAI,gBAAgB,CAAC,GAAG;IACvD,MAAM,WAAW,SAAS,YAAY;IACtC,MAAM,eAAe,iLAAmB,CAAC;QAAE;QAAU;IAAS;IAC9D,MAAM,cAAc,IAAI,kBAAkB,IAAI;IAC9C,KAAK,CAAC;QACF,MAAM,YAAY,QAAQ,CAAC;QAC3B,MAAM,aAAa,KAAK;IAC5B,CAAC;IACD,OAAO;AACX;AACA,MAAM;IACF,CAAA,IAAK,CAAC;IACN;;;KAGC,GACD,YAAY,IAAI,EAAE,IAAI,CAAE;QACpB,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,CAAA,IAAK,GAAG;IACjB;IACA,gDAAgD,GAChD,MAAM,SAAS,MAAM,EAAE;QACnB,MAAM,mBAAmB,oOAAuB,CAAC;QACjD,MAAM,IAAI,CAAC,CAAA,IAAK,CAAC,MAAM,GAAG,MAAM,CAAC,IAAI,eAAe;YAChD,MAAM,OAAM,KAAK;gBACb,MAAM,iBAAiB,KAAK,CAAC;YACjC;QACJ;QACA,OAAO,MAAM,iBAAiB,KAAK;IACvC;AACJ;AACA,MAAM;IACF,CAAA,OAAQ,CAAC;IACT,oEAAoE,GACpE,UAAU,IAAI,MAAM;IACpB;;;KAGC,GACD,YAAY,IAAI,EAAE,OAAO,CAAE;QACvB,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,CAAA,OAAQ,GAAG;IACpB;IACA,gDAAgD,GAChD,MAAM,SAAS,MAAM,EAAE;QACnB,MAAM,YAAY,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,kBACjC,mPAA4B,CAAC,UAC7B,4QAAmC,CAAC;QAC1C,KAAK,MAAM,CAAC,MAAM,MAAM,IAAI,IAAI,CAAC,OAAO,CAAE;YACtC,MAAM,OAAO,MAAM,MAAM,QAAQ,CAAC;YAClC,IAAI,IAAI,CAAC,CAAA,OAAQ,EAAE,sBAAsB;gBACrC,mBAAmB;gBACnB,IAAI,CAAC,CAAA,OAAQ,CAAC,oBAAoB,CAAC;oBAAE,MAAM,MAAM,IAAI;oBAAE,GAAG,IAAI;gBAAC;YACnE;YACA,UAAU,GAAG,CAAC,MAAM;QACxB;QACA,OAAO,MAAM,UAAU,KAAK;IAChC;AACJ;AAMO,eAAe,gBAAgB,KAAK,EAAE,OAAO;IAChD,MAAM,WAAW,6BAA6B,OAAO;IACrD,MAAM,SAAS,MAAM,QAAQ;IAC7B,gDAAgD;IAChD,OAAO;QAAE,KAAK,OAAO,EAAE,CAAC,CAAC,GAAG,GAAG;QAAE;IAAO;AAC5C;AAMO,SAAS,6BAA6B,KAAK,EAAE,OAAO;IACvD,MAAM,UAAU,IAAI,uBAAuB,IAAI;IAC/C,KAAK,MAAM,QAAQ,MAAO;QACtB,MAAM,OAAO,KAAK,IAAI,CAAC,KAAK,CAAC;QAC7B,IAAI,IAAI,CAAC,EAAE,KAAK,MAAM,IAAI,CAAC,EAAE,KAAK,KAAK;YACnC,KAAK,KAAK;QACd;QACA,IAAI,MAAM;QACV,KAAK,MAAM,CAAC,GAAG,KAAK,IAAI,KAAK,OAAO,GAAI;YACpC,IAAI,MAAM,KAAK,MAAM,GAAG,GAAG;gBACvB,IAAI,OAAO,CAAC,GAAG,CAAC,MAAM,IAAI,kBAAkB,KAAK,IAAI,CAAC,MAAM;gBAC5D;YACJ;YACA,IAAI,aAAa,IAAI,OAAO,CAAC,GAAG,CAAC;YACjC,IAAI,cAAc,MAAM;gBACpB,MAAM,UAAU,QAAQ,UAAU,OAAO,GAAG,IAAI,IAAI,CAAC,CAAC,EAAE,MAAM;gBAC9D,aAAa,IAAI,uBAAuB,SAAS;gBACjD,IAAI,OAAO,CAAC,GAAG,CAAC,MAAM;YAC1B;YACA,IAAI,CAAC,CAAC,sBAAsB,sBAAsB,GAAG;gBACjD,MAAM,IAAI,MAAM,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,kCAAkC,CAAC;YACrE;YACA,MAAM;QACV;IACJ;IACA,wFAAwF,GACxF,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,GAAG,IAAI,gBAAgB,CAAC,GAAG;IACvD,MAAM,WAAW,SAAS,YAAY;IACtC,MAAM,eAAe,iLAAmB,CAAC;QAAE;QAAU;IAAS;IAC9D,KAAK,CAAC;QACF,MAAM,OAAO,MAAM,QAAQ,QAAQ,CAAC;QACpC,IAAI,SAAS,sBAAsB;YAC/B,QAAQ,oBAAoB,CAAC;gBAAE,MAAM;gBAAI,GAAG,IAAI;YAAC;QACrD;QACA,MAAM,aAAa,KAAK;IAC5B,CAAC;IACD,OAAO;AACX;AACA;;;;CAIC,GACD,eAAe,QAAQ,WAAW;IAC9B,gBAAgB,GAChB,MAAM,SAAS,EAAE;IACjB,MAAM,YAAY,MAAM,CAAC,IAAI,eAAe;QACxC,OAAM,KAAK;YACP,OAAO,IAAI,CAAC;QAChB;IACJ;IACA,OAAO;AACX,EACA,kCAAkC","ignoreList":[0]}},
    {"offset": {"line": 1121, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/car.js"],"sourcesContent":["import { CarBlockIterator, CarWriter } from '@ipld/car';\nimport * as dagCBOR from '@ipld/dag-cbor';\nimport varint from 'varint';\n/**\n * @typedef {import('@ipld/unixfs').Block} Block\n */\nexport const code = 0x0202;\n/** Byte length of a CBOR encoded CAR header with zero roots. */\nconst NO_ROOTS_HEADER_LENGTH = 18;\n/** @param {import('./types.js').AnyLink} [root] */\nexport function headerEncodingLength(root) {\n    if (!root)\n        return NO_ROOTS_HEADER_LENGTH;\n    const headerLength = dagCBOR.encode({ version: 1, roots: [root] }).length;\n    const varintLength = varint.encodingLength(headerLength);\n    return varintLength + headerLength;\n}\n/** @param {Block} block */\nexport function blockHeaderEncodingLength(block) {\n    const payloadLength = block.cid.bytes.length + block.bytes.length;\n    const varintLength = varint.encodingLength(payloadLength);\n    return varintLength + block.cid.bytes.length;\n}\n/** @param {Block} block */\nexport function blockEncodingLength(block) {\n    return blockHeaderEncodingLength(block) + block.bytes.length;\n}\n/**\n * @param {Iterable<Block> | AsyncIterable<Block>} blocks\n * @param {import('./types.js').AnyLink} [root]\n * @returns {Promise<import('./types.js').CARFile>}\n */\nexport async function encode(blocks, root) {\n    // @ts-expect-error\n    const { writer, out } = CarWriter.create(root);\n    /** @type {Error?} */\n    let error;\n    void (async () => {\n        try {\n            for await (const block of blocks) {\n                await writer.put(block);\n            }\n        }\n        catch ( /** @type {any} */err) {\n            error = err;\n        }\n        finally {\n            await writer.close();\n        }\n    })();\n    const chunks = [];\n    for await (const chunk of out)\n        chunks.push(chunk);\n    // @ts-expect-error\n    if (error != null)\n        throw error;\n    const roots = root != null ? [root] : [];\n    return Object.assign(new Blob(chunks), { version: 1, roots });\n}\n/** @param {import('./types.js').BlobLike} car */\nexport async function decode(car) {\n    const stream = new BlockStream(car);\n    const blocks = /** @type {Block[]} */ ([]);\n    await stream.pipeTo(new WritableStream({\n        write: (block) => {\n            blocks.push(block);\n        },\n    }));\n    const roots = await stream.getRoots();\n    return { blocks, roots };\n}\n/** @extends {ReadableStream<Block>} */\nexport class BlockStream extends ReadableStream {\n    /** @param {import('./types.js').BlobLike} car */\n    constructor(car) {\n        /** @type {Promise<CarBlockIterator>?} */\n        let blocksPromise = null;\n        const getBlocksIterable = () => {\n            if (blocksPromise)\n                return blocksPromise;\n            blocksPromise = CarBlockIterator.fromIterable(toIterable(car.stream()));\n            return blocksPromise;\n        };\n        /** @type {AsyncIterator<Block>?} */\n        let iterator = null;\n        super({\n            async start() {\n                const blocks = await getBlocksIterable();\n                iterator = /** @type {AsyncIterator<Block>} */ (blocks[Symbol.asyncIterator]());\n            },\n            async pull(controller) {\n                /* c8 ignore next */\n                if (!iterator)\n                    throw new Error('missing blocks iterator');\n                const { value, done } = await iterator.next();\n                if (done)\n                    return controller.close();\n                controller.enqueue(value);\n            },\n        });\n        /** @returns {Promise<import('./types.js').AnyLink[]>} */\n        this.getRoots = async () => {\n            const blocks = await getBlocksIterable();\n            return await blocks.getRoots();\n        };\n    }\n}\n/* c8 ignore start */\n/**\n * {@link ReadableStream} is an async iterable in newer environments, but it's\n * not standard yet. This function normalizes a {@link ReadableStream} to a\n * definite async iterable.\n *\n * @template T\n * @param {ReadableStream<T> | AsyncIterable<T>} stream\n * @returns {AsyncIterable<T>} An async iterable of the contents of the\n *                             {@link stream} (possibly {@link stream} itself).\n */\nfunction toIterable(stream) {\n    return Symbol.asyncIterator in stream\n        ? stream\n        : (async function* () {\n            const reader = stream.getReader();\n            try {\n                while (true) {\n                    const { done, value } = await reader.read();\n                    if (done)\n                        return;\n                    yield value;\n                }\n            }\n            finally {\n                reader.releaseLock();\n            }\n        })();\n}\n/* c8 ignore end */\n//# sourceMappingURL=car.js.map"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AACA;AACA;;;;AAIO,MAAM,OAAO;AACpB,8DAA8D,GAC9D,MAAM,yBAAyB;AAExB,SAAS,qBAAqB,IAAI;IACrC,IAAI,CAAC,MACD,OAAO;IACX,MAAM,eAAe,kKAAc,CAAC;QAAE,SAAS;QAAG,OAAO;YAAC;SAAK;IAAC,GAAG,MAAM;IACzE,MAAM,eAAe,6IAAM,CAAC,cAAc,CAAC;IAC3C,OAAO,eAAe;AAC1B;AAEO,SAAS,0BAA0B,KAAK;IAC3C,MAAM,gBAAgB,MAAM,GAAG,CAAC,KAAK,CAAC,MAAM,GAAG,MAAM,KAAK,CAAC,MAAM;IACjE,MAAM,eAAe,6IAAM,CAAC,cAAc,CAAC;IAC3C,OAAO,eAAe,MAAM,GAAG,CAAC,KAAK,CAAC,MAAM;AAChD;AAEO,SAAS,oBAAoB,KAAK;IACrC,OAAO,0BAA0B,SAAS,MAAM,KAAK,CAAC,MAAM;AAChE;AAMO,eAAe,OAAO,MAAM,EAAE,IAAI;IACrC,mBAAmB;IACnB,MAAM,EAAE,MAAM,EAAE,GAAG,EAAE,GAAG,yKAAS,CAAC,MAAM,CAAC;IACzC,mBAAmB,GACnB,IAAI;IACJ,KAAK,CAAC;QACF,IAAI;YACA,WAAW,MAAM,SAAS,OAAQ;gBAC9B,MAAM,OAAO,GAAG,CAAC;YACrB;QACJ,EACA,OAAQ,gBAAgB,GAAE,KAAK;YAC3B,QAAQ;QACZ,SACQ;YACJ,MAAM,OAAO,KAAK;QACtB;IACJ,CAAC;IACD,MAAM,SAAS,EAAE;IACjB,WAAW,MAAM,SAAS,IACtB,OAAO,IAAI,CAAC;IAChB,mBAAmB;IACnB,IAAI,SAAS,MACT,MAAM;IACV,MAAM,QAAQ,QAAQ,OAAO;QAAC;KAAK,GAAG,EAAE;IACxC,OAAO,OAAO,MAAM,CAAC,IAAI,KAAK,SAAS;QAAE,SAAS;QAAG;IAAM;AAC/D;AAEO,eAAe,OAAO,GAAG;IAC5B,MAAM,SAAS,IAAI,YAAY;IAC/B,MAAM,SAAiC,EAAE;IACzC,MAAM,OAAO,MAAM,CAAC,IAAI,eAAe;QACnC,OAAO,CAAC;YACJ,OAAO,IAAI,CAAC;QAChB;IACJ;IACA,MAAM,QAAQ,MAAM,OAAO,QAAQ;IACnC,OAAO;QAAE;QAAQ;IAAM;AAC3B;AAEO,MAAM,oBAAoB;IAC7B,+CAA+C,GAC/C,YAAY,GAAG,CAAE;QACb,uCAAuC,GACvC,IAAI,gBAAgB;QACpB,MAAM,oBAAoB;YACtB,IAAI,eACA,OAAO;YACX,gBAAgB,uKAAgB,CAAC,YAAY,CAAC,WAAW,IAAI,MAAM;YACnE,OAAO;QACX;QACA,kCAAkC,GAClC,IAAI,WAAW;QACf,KAAK,CAAC;YACF,MAAM;gBACF,MAAM,SAAS,MAAM;gBACrB,WAAgD,MAAM,CAAC,OAAO,aAAa,CAAC;YAChF;YACA,MAAM,MAAK,UAAU;gBACjB,kBAAkB,GAClB,IAAI,CAAC,UACD,MAAM,IAAI,MAAM;gBACpB,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,GAAG,MAAM,SAAS,IAAI;gBAC3C,IAAI,MACA,OAAO,WAAW,KAAK;gBAC3B,WAAW,OAAO,CAAC;YACvB;QACJ;QACA,uDAAuD,GACvD,IAAI,CAAC,QAAQ,GAAG;YACZ,MAAM,SAAS,MAAM;YACrB,OAAO,MAAM,OAAO,QAAQ;QAChC;IACJ;AACJ;AACA,mBAAmB,GACnB;;;;;;;;;CASC,GACD,SAAS,WAAW,MAAM;IACtB,OAAO,OAAO,aAAa,IAAI,SACzB,SACA,AAAC;QACC,MAAM,SAAS,OAAO,SAAS;QAC/B,IAAI;YACA,MAAO,KAAM;gBACT,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,IAAI;gBACzC,IAAI,MACA;gBACJ,MAAM;YACV;QACJ,SACQ;YACJ,OAAO,WAAW;QACtB;IACJ;AACR,EACA,iBAAiB,IACjB,+BAA+B","ignoreList":[0]}},
    {"offset": {"line": 1261, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/deduplication.js"],"sourcesContent":["/** @import { Block } from '@ipld/unixfs' */\n/** @extends {TransformStream<Block, Block>} */\nexport class BlockDeduplicationStream extends TransformStream {\n    constructor() {\n        /** @type {Set<string>} */\n        const seen = new Set();\n        super({\n            transform(block, controller) {\n                const key = block.cid.toString();\n                if (seen.has(key))\n                    return;\n                seen.add(key);\n                controller.enqueue(block);\n            },\n            flush() {\n                seen.clear();\n            },\n        });\n    }\n}\n/**\n * @param {Iterable<Block>} blocks\n * @returns {IterableIterator<Block>}\n */\nexport const dedupe = function* (blocks) {\n    /** @type {Set<string>} */\n    const seen = new Set();\n    for (const b of blocks) {\n        const key = b.cid.toString();\n        if (seen.has(key))\n            continue;\n        seen.add(key);\n        yield b;\n    }\n};\n//# sourceMappingURL=deduplication.js.map"],"names":[],"mappings":"AAAA,0CAA0C,GAC1C,6CAA6C;;;;;;AACtC,MAAM,iCAAiC;IAC1C,aAAc;QACV,wBAAwB,GACxB,MAAM,OAAO,IAAI;QACjB,KAAK,CAAC;YACF,WAAU,KAAK,EAAE,UAAU;gBACvB,MAAM,MAAM,MAAM,GAAG,CAAC,QAAQ;gBAC9B,IAAI,KAAK,GAAG,CAAC,MACT;gBACJ,KAAK,GAAG,CAAC;gBACT,WAAW,OAAO,CAAC;YACvB;YACA;gBACI,KAAK,KAAK;YACd;QACJ;IACJ;AACJ;AAKO,MAAM,SAAS,UAAW,MAAM;IACnC,wBAAwB,GACxB,MAAM,OAAO,IAAI;IACjB,KAAK,MAAM,KAAK,OAAQ;QACpB,MAAM,MAAM,EAAE,GAAG,CAAC,QAAQ;QAC1B,IAAI,KAAK,GAAG,CAAC,MACT;QACJ,KAAK,GAAG,CAAC;QACT,MAAM;IACV;AACJ,GACA,yCAAyC","ignoreList":[0]}},
    {"offset": {"line": 1296, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/sharding.js"],"sourcesContent":["import { DigestMap } from '@storacha/blob-index';\nimport { blockEncodingLength, blockHeaderEncodingLength, encode, headerEncodingLength, } from './car.js';\n/**\n * @typedef {import('./types.js').FileLike} FileLike\n */\n// https://observablehq.com/@gozala/w3up-shard-size\nexport const SHARD_SIZE = 133_169_152;\n/**\n * Shard a set of blocks into a set of CAR files. By default the last block\n * received is assumed to be the DAG root and becomes the CAR root CID for the\n * last CAR output. Set the `rootCID` option to override.\n *\n * @extends {TransformStream<import('@ipld/unixfs').Block, import('./types.js').IndexedCARFile>}\n */\nexport class ShardingStream extends TransformStream {\n    /**\n     * @param {import('./types.js').ShardingOptions} [options]\n     */\n    constructor(options = {}) {\n        const shardSize = options.shardSize ?? SHARD_SIZE;\n        const maxBlockLength = shardSize - headerEncodingLength();\n        /** @type {import('@ipld/unixfs').Block[]} */\n        let blocks = [];\n        /** @type {import('@ipld/unixfs').Block[] | null} */\n        let readyBlocks = null;\n        /** @type {Map<import('./types.js').SliceDigest, import('./types.js').Position>} */\n        let slices = new DigestMap();\n        /** @type {Map<import('./types.js').SliceDigest, import('./types.js').Position> | null} */\n        let readySlices = null;\n        let currentLength = 0;\n        super({\n            async transform(block, controller) {\n                if (readyBlocks != null && readySlices != null) {\n                    controller.enqueue(await encodeCAR(readyBlocks, readySlices));\n                    readyBlocks = null;\n                    readySlices = null;\n                }\n                const blockHeaderLength = blockHeaderEncodingLength(block);\n                const blockLength = blockHeaderLength + block.bytes.length;\n                if (blockLength > maxBlockLength) {\n                    throw new Error(`block will cause CAR to exceed shard size: ${block.cid}`);\n                }\n                if (blocks.length && currentLength + blockLength > maxBlockLength) {\n                    readyBlocks = blocks;\n                    readySlices = slices;\n                    blocks = [];\n                    slices = new DigestMap();\n                    currentLength = 0;\n                }\n                blocks.push(block);\n                slices.set(block.cid.multihash, [\n                    headerEncodingLength() + currentLength + blockHeaderLength,\n                    block.bytes.length,\n                ]);\n                currentLength += blockLength;\n            },\n            async flush(controller) {\n                if (readyBlocks != null && readySlices != null) {\n                    controller.enqueue(await encodeCAR(readyBlocks, readySlices));\n                }\n                const rootBlock = blocks.at(-1);\n                if (rootBlock == null)\n                    return;\n                const rootCID = options.rootCID ?? rootBlock.cid;\n                const headerLength = headerEncodingLength(rootCID);\n                // if adding CAR root overflows the shard limit we move overflowing\n                // blocks into another CAR.\n                if (headerLength + currentLength > shardSize) {\n                    const overage = headerLength + currentLength - shardSize;\n                    const overflowBlocks = [];\n                    let overflowCurrentLength = 0;\n                    while (overflowCurrentLength < overage) {\n                        const block = blocks[blocks.length - 1];\n                        blocks.pop();\n                        slices.delete(block.cid.multihash);\n                        overflowBlocks.unshift(block);\n                        overflowCurrentLength += blockEncodingLength(block);\n                        // need at least 1 block in original shard\n                        if (blocks.length < 1)\n                            throw new Error(`block will cause CAR to exceed shard size: ${block.cid}`);\n                    }\n                    controller.enqueue(await encodeCAR(blocks, slices));\n                    // Finally, re-calc block positions from blocks we moved out of the\n                    // CAR that was too big.\n                    overflowCurrentLength = 0;\n                    /** @type {Map<import('./types.js').SliceDigest, import('./types.js').Position>} */\n                    const overflowSlices = new DigestMap();\n                    for (const block of overflowBlocks) {\n                        const overflowBlockHeaderLength = blockHeaderEncodingLength(block);\n                        overflowSlices.set(block.cid.multihash, [\n                            headerLength + overflowCurrentLength + overflowBlockHeaderLength,\n                            block.bytes.length,\n                        ]);\n                        overflowCurrentLength +=\n                            overflowBlockHeaderLength + block.bytes.length;\n                    }\n                    controller.enqueue(await encodeCAR(overflowBlocks, overflowSlices, rootCID));\n                }\n                else {\n                    // adjust offsets for longer header in final shard\n                    const diff = headerLength - headerEncodingLength();\n                    for (const slice of slices.values()) {\n                        slice[0] += diff;\n                    }\n                    controller.enqueue(await encodeCAR(blocks, slices, rootCID));\n                }\n            },\n        });\n    }\n}\n/**\n * Default comparator for FileLikes. Sorts by file name in ascending order.\n *\n * @param {FileLike} a\n * @param {FileLike} b\n * @param {(file: FileLike) => string} getComparedValue - given a file being sorted, return the value by which its order should be determined, if it is different than the file object itself (e.g. file.name)\n */\nexport const defaultFileComparator = (a, b, getComparedValue = (file) => file.name) => {\n    return ascending(a, b, getComparedValue);\n};\n/**\n * a comparator for sorting in ascending order. Use with Sorted or Array#sort.\n *\n * @template T\n * @param {T} a\n * @param {T} b\n * @param {(i: T) => any} getComparedValue - given an item being sorted, return the value by which it should be sorted, if it is different than the item\n */\nfunction ascending(a, b, getComparedValue) {\n    const ask = getComparedValue(a);\n    const bsk = getComparedValue(b);\n    if (ask === bsk)\n        return 0;\n    else if (ask < bsk)\n        return -1;\n    return 1;\n}\n/**\n * @param {Iterable<import('@ipld/unixfs').Block>} blocks\n * @param {Map<import('./types.js').SliceDigest, import('./types.js').Position>} slices\n * @param {import('./types.js').AnyLink} [root]\n * @returns {Promise<import('./types.js').IndexedCARFile>}\n */\nconst encodeCAR = async (blocks, slices, root) => Object.assign(await encode(blocks, root), { slices });\n//# sourceMappingURL=sharding.js.map"],"names":[],"mappings":";;;;;;;;AAAA;AAAA;AACA;;;AAKO,MAAM,aAAa;AAQnB,MAAM,uBAAuB;IAChC;;KAEC,GACD,YAAY,UAAU,CAAC,CAAC,CAAE;QACtB,MAAM,YAAY,QAAQ,SAAS,IAAI;QACvC,MAAM,iBAAiB,YAAY,IAAA,wLAAoB;QACvD,2CAA2C,GAC3C,IAAI,SAAS,EAAE;QACf,kDAAkD,GAClD,IAAI,cAAc;QAClB,iFAAiF,GACjF,IAAI,SAAS,IAAI,oLAAS;QAC1B,wFAAwF,GACxF,IAAI,cAAc;QAClB,IAAI,gBAAgB;QACpB,KAAK,CAAC;YACF,MAAM,WAAU,KAAK,EAAE,UAAU;gBAC7B,IAAI,eAAe,QAAQ,eAAe,MAAM;oBAC5C,WAAW,OAAO,CAAC,MAAM,UAAU,aAAa;oBAChD,cAAc;oBACd,cAAc;gBAClB;gBACA,MAAM,oBAAoB,IAAA,6LAAyB,EAAC;gBACpD,MAAM,cAAc,oBAAoB,MAAM,KAAK,CAAC,MAAM;gBAC1D,IAAI,cAAc,gBAAgB;oBAC9B,MAAM,IAAI,MAAM,CAAC,2CAA2C,EAAE,MAAM,GAAG,EAAE;gBAC7E;gBACA,IAAI,OAAO,MAAM,IAAI,gBAAgB,cAAc,gBAAgB;oBAC/D,cAAc;oBACd,cAAc;oBACd,SAAS,EAAE;oBACX,SAAS,IAAI,oLAAS;oBACtB,gBAAgB;gBACpB;gBACA,OAAO,IAAI,CAAC;gBACZ,OAAO,GAAG,CAAC,MAAM,GAAG,CAAC,SAAS,EAAE;oBAC5B,IAAA,wLAAoB,MAAK,gBAAgB;oBACzC,MAAM,KAAK,CAAC,MAAM;iBACrB;gBACD,iBAAiB;YACrB;YACA,MAAM,OAAM,UAAU;gBAClB,IAAI,eAAe,QAAQ,eAAe,MAAM;oBAC5C,WAAW,OAAO,CAAC,MAAM,UAAU,aAAa;gBACpD;gBACA,MAAM,YAAY,OAAO,EAAE,CAAC,CAAC;gBAC7B,IAAI,aAAa,MACb;gBACJ,MAAM,UAAU,QAAQ,OAAO,IAAI,UAAU,GAAG;gBAChD,MAAM,eAAe,IAAA,wLAAoB,EAAC;gBAC1C,mEAAmE;gBACnE,2BAA2B;gBAC3B,IAAI,eAAe,gBAAgB,WAAW;oBAC1C,MAAM,UAAU,eAAe,gBAAgB;oBAC/C,MAAM,iBAAiB,EAAE;oBACzB,IAAI,wBAAwB;oBAC5B,MAAO,wBAAwB,QAAS;wBACpC,MAAM,QAAQ,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE;wBACvC,OAAO,GAAG;wBACV,OAAO,MAAM,CAAC,MAAM,GAAG,CAAC,SAAS;wBACjC,eAAe,OAAO,CAAC;wBACvB,yBAAyB,IAAA,uLAAmB,EAAC;wBAC7C,0CAA0C;wBAC1C,IAAI,OAAO,MAAM,GAAG,GAChB,MAAM,IAAI,MAAM,CAAC,2CAA2C,EAAE,MAAM,GAAG,EAAE;oBACjF;oBACA,WAAW,OAAO,CAAC,MAAM,UAAU,QAAQ;oBAC3C,mEAAmE;oBACnE,wBAAwB;oBACxB,wBAAwB;oBACxB,iFAAiF,GACjF,MAAM,iBAAiB,IAAI,oLAAS;oBACpC,KAAK,MAAM,SAAS,eAAgB;wBAChC,MAAM,4BAA4B,IAAA,6LAAyB,EAAC;wBAC5D,eAAe,GAAG,CAAC,MAAM,GAAG,CAAC,SAAS,EAAE;4BACpC,eAAe,wBAAwB;4BACvC,MAAM,KAAK,CAAC,MAAM;yBACrB;wBACD,yBACI,4BAA4B,MAAM,KAAK,CAAC,MAAM;oBACtD;oBACA,WAAW,OAAO,CAAC,MAAM,UAAU,gBAAgB,gBAAgB;gBACvE,OACK;oBACD,kDAAkD;oBAClD,MAAM,OAAO,eAAe,IAAA,wLAAoB;oBAChD,KAAK,MAAM,SAAS,OAAO,MAAM,GAAI;wBACjC,KAAK,CAAC,EAAE,IAAI;oBAChB;oBACA,WAAW,OAAO,CAAC,MAAM,UAAU,QAAQ,QAAQ;gBACvD;YACJ;QACJ;IACJ;AACJ;AAQO,MAAM,wBAAwB,CAAC,GAAG,GAAG,mBAAmB,CAAC,OAAS,KAAK,IAAI;IAC9E,OAAO,UAAU,GAAG,GAAG;AAC3B;AACA;;;;;;;CAOC,GACD,SAAS,UAAU,CAAC,EAAE,CAAC,EAAE,gBAAgB;IACrC,MAAM,MAAM,iBAAiB;IAC7B,MAAM,MAAM,iBAAiB;IAC7B,IAAI,QAAQ,KACR,OAAO;SACN,IAAI,MAAM,KACX,OAAO,CAAC;IACZ,OAAO;AACX;AACA;;;;;CAKC,GACD,MAAM,YAAY,OAAO,QAAQ,QAAQ,OAAS,OAAO,MAAM,CAAC,MAAM,IAAA,0KAAM,EAAC,QAAQ,OAAO;QAAE;IAAO,IACrG,oCAAoC","ignoreList":[0]}},
    {"offset": {"line": 1425, "column": 0}, "map": {"version":3,"sources":["file:///home/driemworks/fangorn/website/node_modules/%40storacha/upload-client/dist/index.js"],"sourcesContent":["import * as PieceHasher from '@web3-storage/data-segment/multihash';\nimport { Storefront } from '@storacha/filecoin-client';\nimport * as Link from 'multiformats/link';\nimport * as raw from 'multiformats/codecs/raw';\nimport * as Digest from 'multiformats/hashes/digest';\nimport { sha256 } from 'multiformats/hashes/sha2';\nimport * as Blob from './blob/index.js';\nimport * as BlobAdd from './blob/add.js';\nimport * as Index from './index/index.js';\nimport * as IndexAdd from './index/add.js';\nimport * as Upload from './upload/index.js';\nimport * as UploadAdd from './upload/add.js';\nimport * as UnixFS from './unixfs.js';\nimport * as CAR from './car.js';\nimport { BlockDeduplicationStream, dedupe } from './deduplication.js';\nimport { ShardingStream, defaultFileComparator, SHARD_SIZE, } from './sharding.js';\nimport { ShardedDAGIndex, indexShardedDAG } from '@storacha/blob-index';\nexport { Blob, Index, Upload, UnixFS, CAR };\nexport * from './sharding.js';\nexport { receiptsEndpoint } from './service.js';\nexport * as Receipt from './receipts.js';\n/** @param {Uint8Array} bytes */\nconst isSubArray = (bytes) => bytes.byteOffset !== 0 || bytes.buffer.byteLength !== bytes.byteLength;\n/**\n * Uploads a file to the service and returns the root data CID for the\n * generated DAG.\n *\n * Required delegated capability proofs: `blob/add`, `index/add`,\n * `filecoin/offer`, `upload/add`\n *\n * @param {import('./types.js').InvocationConfig|import('./types.js').InvocationConfigurator} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`, or a\n * function that generates this object.\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/add`, `index/add`, `filecoin/offer` and\n * `upload/add` delegated capability.\n * @param {import('./types.js').BlobLike} file File data.\n * @param {import('./types.js').UploadFileOptions} [options]\n */\nexport async function uploadFile(conf, file, options = {}) {\n    const shardSize = options.shardSize ?? SHARD_SIZE;\n    if (file.size != null && file.size < shardSize) {\n        const { blocks, cid } = await UnixFS.encodeFile(file, options);\n        return await uploadBlocks(conf, blocks, { rootCID: cid, ...options });\n    }\n    return await uploadBlockStream(conf, UnixFS.createFileEncoderStream(file, options), options);\n}\n/**\n * Uploads a directory of files to the service and returns the root data CID\n * for the generated DAG. All files are added to a container directory, with\n * paths in file names preserved.\n *\n * Required delegated capability proofs: `blob/add`, `index/add`,\n * `filecoin/offer`, `upload/add`\n *\n * @param {import('./types.js').InvocationConfig|import('./types.js').InvocationConfigurator} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`, or a\n * function that generates this object\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/add`, `index/add`, `filecoin/offer` and\n * `upload/add` delegated capability.\n * @param {import('./types.js').FileLike[]} files  Files that should be in the directory.\n * To ensure determinism in the IPLD encoding, files are automatically sorted by `file.name`.\n * To retain the order of the files as passed in the array, set `customOrder` option to `true`.\n * @param {import('./types.js').UploadDirectoryOptions} [options]\n */\nexport async function uploadDirectory(conf, files, options = {}) {\n    const { customOrder = false } = options;\n    const entries = customOrder ? files : [...files].sort(defaultFileComparator);\n    let size = 0;\n    let isKnownSize = true;\n    for (const entry of entries) {\n        if (entry.size == null) {\n            isKnownSize = false;\n            break;\n        }\n        size += entry.size;\n    }\n    const shardSize = options.shardSize ?? SHARD_SIZE;\n    if (isKnownSize && size < shardSize) {\n        const { blocks, cid } = await UnixFS.encodeDirectory(entries, options);\n        return await uploadBlocks(conf, blocks, { rootCID: cid, ...options });\n    }\n    return await uploadBlockStream(conf, UnixFS.createDirectoryEncoderStream(entries, options), options);\n}\n/**\n * Uploads a CAR file to the service.\n *\n * The difference between this function and `Store.add` is that the CAR file is\n * automatically sharded and an \"upload\" is registered, linking the individual\n * shards (see `Upload.add`).\n *\n * Use the `onShardStored` callback to obtain the CIDs of the CAR file shards.\n *\n * Required delegated capability proofs: `blob/add`, `index/add`,\n * `filecoin/offer`, `upload/add`\n *\n * @param {import('./types.js').InvocationConfig|import('./types.js').InvocationConfigurator} conf Configuration\n * for the UCAN invocation. An object with `issuer`, `with` and `proofs`, or a\n * function that generates this object\n *\n * The `issuer` is the signing authority that is issuing the UCAN\n * invocation(s). It is typically the user _agent_.\n *\n * The `with` is the resource the invocation applies to. It is typically the\n * DID of a space.\n *\n * The `proofs` are a set of capability delegations that prove the issuer\n * has the capability to perform the action.\n *\n * The issuer needs the `blob/add`, `index/add`, `filecoin/offer` and `upload/add` delegated capability.\n * @param {import('./types.js').BlobLike} car CAR file.\n * @param {import('./types.js').UploadOptions} [options]\n */\nexport async function uploadCAR(conf, car, options = {}) {\n    const shardSize = options.shardSize ?? SHARD_SIZE;\n    if (car.size != null && car.size < shardSize) {\n        const { blocks, roots } = await CAR.decode(car);\n        return await uploadBlocks(conf, blocks, { rootCID: roots[0], ...options });\n    }\n    const blocks = new CAR.BlockStream(car);\n    options.rootCID = options.rootCID ?? (await blocks.getRoots())[0];\n    return await uploadBlockStream(conf, blocks, options);\n}\n/**\n * @param {import('./types.js').InvocationConfig|import('./types.js').InvocationConfigurator} conf\n * @param {ReadableStream<import('@ipld/unixfs').Block>} blocks\n * @param {import('./types.js').UploadOptions} [options]\n * @returns {Promise<import('./types.js').AnyLink>}\n */\nexport async function uploadBlockStream(conf, blocks, { pieceHasher = PieceHasher, ...options } = {}) {\n    /** @type {import('./types.js').InvocationConfigurator} */\n    const configure = typeof conf === 'function' ? conf : () => conf;\n    /** @type {Array<Map<import('./types.js').SliceDigest, import('./types.js').Position>>} */\n    const shardIndexes = [];\n    /** @type {import('./types.js').CARLink[]} */\n    const shards = [];\n    /** @type {import('./types.js').AnyLink?} */\n    let root = null;\n    if (options.dedupe == null || options.dedupe === true) {\n        blocks = blocks.pipeThrough(new BlockDeduplicationStream());\n    }\n    await blocks\n        .pipeThrough(new ShardingStream(options))\n        .pipeThrough(\n    /** @type {TransformStream<import('./types.js').IndexedCARFile, import('./types.js').CARMetadata>} */\n    (new TransformStream({\n        async transform(car, controller) {\n            const bytes = new Uint8Array(await car.arrayBuffer());\n            const digest = await sha256.digest(bytes);\n            const conf = await configure([\n                {\n                    can: BlobAdd.ability,\n                    nb: BlobAdd.input(digest, bytes.length),\n                },\n            ]);\n            // Invoke blob/add and write bytes to write target\n            await Blob.add(conf, digest, bytes, options);\n            const cid = Link.create(CAR.code, digest);\n            let piece;\n            if (pieceHasher) {\n                const multihashDigest = await pieceHasher.digest(bytes);\n                /** @type {import('@storacha/capabilities/types').PieceLink} */\n                piece = Link.create(raw.code, multihashDigest);\n                const content = Link.create(raw.code, digest);\n                // Invoke filecoin/offer for data\n                const result = await Storefront.filecoinOffer({\n                    issuer: conf.issuer,\n                    audience: conf.audience,\n                    // Resource of invocation is the issuer did for being self issued\n                    with: conf.issuer.did(),\n                    proofs: conf.proofs,\n                }, content, piece, options);\n                if (result.out.error) {\n                    throw new Error('failed to offer piece for aggregation into filecoin deal', { cause: result.out.error });\n                }\n            }\n            const { version, roots, size, slices } = car;\n            controller.enqueue({ version, roots, size, cid, piece, slices });\n        },\n    })))\n        .pipeTo(new WritableStream({\n        write(meta) {\n            root = root || meta.roots[0];\n            shards.push(meta.cid);\n            // Make copies of digests that are views on bigger byte arrays. This\n            // prevents memory leak where the bytes for the rest of the CAR cannot\n            // be released because the digest is a view over just a small portion\n            // of the chunk.\n            for (const [s, p] of meta.slices) {\n                if (isSubArray(s.bytes)) {\n                    meta.slices.set(Digest.decode(s.bytes.slice()), p);\n                }\n            }\n            // add the CAR shard itself to the slices\n            meta.slices.set(meta.cid.multihash, [0, meta.size]);\n            shardIndexes.push(meta.slices);\n            if (options.onShardStored)\n                options.onShardStored(meta);\n        },\n    }));\n    /* c8 ignore next */\n    if (!root)\n        throw new Error('missing root CID');\n    const indexBytes = await indexShardedDAG(root, shards, shardIndexes);\n    /* c8 ignore next 3 */\n    if (!indexBytes.ok) {\n        throw new Error('failed to archive DAG index', { cause: indexBytes.error });\n    }\n    const indexDigest = await sha256.digest(indexBytes.ok);\n    const indexLink = Link.create(CAR.code, indexDigest);\n    const [blobAddConf, indexAddConf, uploadAddConf] = await Promise.all([\n        configure([\n            {\n                can: BlobAdd.ability,\n                nb: BlobAdd.input(indexDigest, indexBytes.ok.length),\n            },\n        ]),\n        configure([\n            {\n                can: IndexAdd.ability,\n                nb: IndexAdd.input(indexLink),\n            },\n        ]),\n        configure([\n            {\n                can: UploadAdd.ability,\n                nb: UploadAdd.input(root, shards),\n            },\n        ]),\n    ]);\n    // Store the index in the space\n    await Blob.add(blobAddConf, indexDigest, indexBytes.ok, options);\n    // Register the index with the service\n    await Index.add(indexAddConf, indexLink, options);\n    // Register an upload with the service\n    await Upload.add(uploadAddConf, root, shards, options);\n    return root;\n}\n/**\n * @param {import('./types.js').InvocationConfig|import('./types.js').InvocationConfigurator} conf\n * @param {Iterable<import('@ipld/unixfs').Block>} blocks\n * @param {import('./types.js').UploadOptions} [options]\n * @returns {Promise<import('./types.js').AnyLink>}\n */\nexport async function uploadBlocks(conf, blocks, { pieceHasher = PieceHasher, ...options } = {}) {\n    /** @type {import('./types.js').InvocationConfigurator} */\n    const configure = typeof conf === 'function' ? conf : () => conf;\n    if (options.dedupe == null || options.dedupe === true) {\n        blocks = dedupe(blocks);\n    }\n    /** @type {import('./types.js').IndexedCARFile} */\n    let car;\n    const blockStream = new ReadableStream({\n        pull(controller) {\n            for (const b of blocks) {\n                controller.enqueue(b);\n            }\n            controller.close();\n        },\n    });\n    // encode indexed CAR\n    await blockStream\n        .pipeThrough(new ShardingStream({ ...options, shardSize: Infinity }))\n        .pipeTo(new WritableStream({\n        write: (c) => {\n            car = c;\n        },\n    }));\n    /* c8 ignore next 2 */\n    // @ts-expect-error no used before defined\n    if (!car)\n        throw new Error('missing CAR output');\n    const root = car.roots[0];\n    const bytes = new Uint8Array(await car.arrayBuffer());\n    const digest = await sha256.digest(bytes);\n    const [shardLink, indexLink] = await Promise.all([\n        (async () => {\n            const conf = await configure([\n                {\n                    can: BlobAdd.ability,\n                    nb: BlobAdd.input(digest, bytes.length),\n                },\n            ]);\n            // Invoke blob/add and write bytes to write target\n            await Blob.add(conf, digest, bytes, options);\n            const cid = Link.create(CAR.code, digest);\n            let piece;\n            if (pieceHasher) {\n                const multihashDigest = await pieceHasher.digest(bytes);\n                /** @type {import('@storacha/capabilities/types').PieceLink} */\n                piece = Link.create(raw.code, multihashDigest);\n                // Invoke filecoin/offer for data\n                const result = await Storefront.filecoinOffer({\n                    issuer: conf.issuer,\n                    audience: conf.audience,\n                    // Resource of invocation is the issuer did for being self issued\n                    with: conf.issuer.did(),\n                    proofs: conf.proofs,\n                }, Link.create(raw.code, digest), piece, options);\n                if (result.out.error) {\n                    throw new Error('failed to offer piece for aggregation into filecoin deal', { cause: result.out.error });\n                }\n            }\n            const { version, roots, size, slices } = car;\n            options.onShardStored?.({ version, roots, size, piece, cid, slices });\n            return cid;\n        })(),\n        (async () => {\n            const index = ShardedDAGIndex.create(root);\n            for (const [slice, pos] of car.slices) {\n                index.setSlice(digest, slice, pos);\n            }\n            // add the CAR shard itself to the slices\n            index.setSlice(digest, digest, [0, car.size]);\n            const indexBytes = await index.archive();\n            /* c8 ignore next 5 */\n            if (!indexBytes.ok) {\n                throw new Error('failed to archive DAG index', {\n                    cause: indexBytes.error,\n                });\n            }\n            const indexDigest = await sha256.digest(indexBytes.ok);\n            const indexLink = Link.create(CAR.code, indexDigest);\n            const conf = await configure([\n                {\n                    can: BlobAdd.ability,\n                    nb: BlobAdd.input(indexDigest, indexBytes.ok.length),\n                },\n            ]);\n            // Store the index in the space\n            await Blob.add(conf, indexDigest, indexBytes.ok, options);\n            return indexLink;\n        })(),\n    ]);\n    await Promise.all([\n        (async () => {\n            const conf = await configure([\n                {\n                    can: IndexAdd.ability,\n                    nb: IndexAdd.input(indexLink),\n                },\n            ]);\n            // Register the index with the service\n            await Index.add(conf, indexLink, options);\n        })(),\n        (async () => {\n            const conf = await configure([\n                {\n                    can: UploadAdd.ability,\n                    nb: UploadAdd.input(root, [shardLink]),\n                },\n            ]);\n            // Register an upload with the service\n            await Upload.add(conf, root, [shardLink], options);\n        })(),\n    ]);\n    return root;\n}\n//# sourceMappingURL=index.js.map"],"names":[],"mappings":";;;;;;;;;;;;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;;;;;;;;;;;;;;;;;;;;;;AACA,8BAA8B,GAC9B,MAAM,aAAa,CAAC,QAAU,MAAM,UAAU,KAAK,KAAK,MAAM,MAAM,CAAC,UAAU,KAAK,MAAM,UAAU;AA0B7F,eAAe,WAAW,IAAI,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC;IACrD,MAAM,YAAY,QAAQ,SAAS,IAAI,mLAAU;IACjD,IAAI,KAAK,IAAI,IAAI,QAAQ,KAAK,IAAI,GAAG,WAAW;QAC5C,MAAM,EAAE,MAAM,EAAE,GAAG,EAAE,GAAG,MAAM,iLAAiB,CAAC,MAAM;QACtD,OAAO,MAAM,aAAa,MAAM,QAAQ;YAAE,SAAS;YAAK,GAAG,OAAO;QAAC;IACvE;IACA,OAAO,MAAM,kBAAkB,MAAM,8LAA8B,CAAC,MAAM,UAAU;AACxF;AA6BO,eAAe,gBAAgB,IAAI,EAAE,KAAK,EAAE,UAAU,CAAC,CAAC;IAC3D,MAAM,EAAE,cAAc,KAAK,EAAE,GAAG;IAChC,MAAM,UAAU,cAAc,QAAQ;WAAI;KAAM,CAAC,IAAI,CAAC,8LAAqB;IAC3E,IAAI,OAAO;IACX,IAAI,cAAc;IAClB,KAAK,MAAM,SAAS,QAAS;QACzB,IAAI,MAAM,IAAI,IAAI,MAAM;YACpB,cAAc;YACd;QACJ;QACA,QAAQ,MAAM,IAAI;IACtB;IACA,MAAM,YAAY,QAAQ,SAAS,IAAI,mLAAU;IACjD,IAAI,eAAe,OAAO,WAAW;QACjC,MAAM,EAAE,MAAM,EAAE,GAAG,EAAE,GAAG,MAAM,sLAAsB,CAAC,SAAS;QAC9D,OAAO,MAAM,aAAa,MAAM,QAAQ;YAAE,SAAS;YAAK,GAAG,OAAO;QAAC;IACvE;IACA,OAAO,MAAM,kBAAkB,MAAM,mMAAmC,CAAC,SAAS,UAAU;AAChG;AA8BO,eAAe,UAAU,IAAI,EAAE,GAAG,EAAE,UAAU,CAAC,CAAC;IACnD,MAAM,YAAY,QAAQ,SAAS,IAAI,mLAAU;IACjD,IAAI,IAAI,IAAI,IAAI,QAAQ,IAAI,IAAI,GAAG,WAAW;QAC1C,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,0KAAU,CAAC;QAC3C,OAAO,MAAM,aAAa,MAAM,QAAQ;YAAE,SAAS,KAAK,CAAC,EAAE;YAAE,GAAG,OAAO;QAAC;IAC5E;IACA,MAAM,SAAS,IAAI,+KAAe,CAAC;IACnC,QAAQ,OAAO,GAAG,QAAQ,OAAO,IAAI,CAAC,MAAM,OAAO,QAAQ,EAAE,CAAC,CAAC,EAAE;IACjE,OAAO,MAAM,kBAAkB,MAAM,QAAQ;AACjD;AAOO,eAAe,kBAAkB,IAAI,EAAE,MAAM,EAAE,EAAE,cAAc,2KAAW,EAAE,GAAG,SAAS,GAAG,CAAC,CAAC;IAChG,wDAAwD,GACxD,MAAM,YAAY,OAAO,SAAS,aAAa,OAAO,IAAM;IAC5D,wFAAwF,GACxF,MAAM,eAAe,EAAE;IACvB,2CAA2C,GAC3C,MAAM,SAAS,EAAE;IACjB,0CAA0C,GAC1C,IAAI,OAAO;IACX,IAAI,QAAQ,MAAM,IAAI,QAAQ,QAAQ,MAAM,KAAK,MAAM;QACnD,SAAS,OAAO,WAAW,CAAC,IAAI,sMAAwB;IAC5D;IACA,MAAM,OACD,WAAW,CAAC,IAAI,uLAAc,CAAC,UAC/B,WAAW,CAEf,IAAI,gBAAgB;QACjB,MAAM,WAAU,GAAG,EAAE,UAAU;YAC3B,MAAM,QAAQ,IAAI,WAAW,MAAM,IAAI,WAAW;YAClD,MAAM,SAAS,MAAM,qLAAM,CAAC,MAAM,CAAC;YACnC,MAAM,OAAO,MAAM,UAAU;gBACzB;oBACI,KAAK,mLAAe;oBACpB,IAAI,iLAAa,CAAC,QAAQ,MAAM,MAAM;gBAC1C;aACH;YACD,kDAAkD;YAClD,MAAM,+KAAQ,CAAC,MAAM,QAAQ,OAAO;YACpC,MAAM,MAAM,gLAAW,CAAC,wKAAQ,EAAE;YAClC,IAAI;YACJ,IAAI,aAAa;gBACb,MAAM,kBAAkB,MAAM,YAAY,MAAM,CAAC;gBACjD,6DAA6D,GAC7D,QAAQ,gLAAW,CAAC,uKAAQ,EAAE;gBAC9B,MAAM,UAAU,gLAAW,CAAC,uKAAQ,EAAE;gBACtC,iCAAiC;gBACjC,MAAM,SAAS,MAAM,6NAAU,CAAC,aAAa,CAAC;oBAC1C,QAAQ,KAAK,MAAM;oBACnB,UAAU,KAAK,QAAQ;oBACvB,iEAAiE;oBACjE,MAAM,KAAK,MAAM,CAAC,GAAG;oBACrB,QAAQ,KAAK,MAAM;gBACvB,GAAG,SAAS,OAAO;gBACnB,IAAI,OAAO,GAAG,CAAC,KAAK,EAAE;oBAClB,MAAM,IAAI,MAAM,4DAA4D;wBAAE,OAAO,OAAO,GAAG,CAAC,KAAK;oBAAC;gBAC1G;YACJ;YACA,MAAM,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,GAAG;YACzC,WAAW,OAAO,CAAC;gBAAE;gBAAS;gBAAO;gBAAM;gBAAK;gBAAO;YAAO;QAClE;IACJ,IACK,MAAM,CAAC,IAAI,eAAe;QAC3B,OAAM,IAAI;YACN,OAAO,QAAQ,KAAK,KAAK,CAAC,EAAE;YAC5B,OAAO,IAAI,CAAC,KAAK,GAAG;YACpB,oEAAoE;YACpE,sEAAsE;YACtE,qEAAqE;YACrE,gBAAgB;YAChB,KAAK,MAAM,CAAC,GAAG,EAAE,IAAI,KAAK,MAAM,CAAE;gBAC9B,IAAI,WAAW,EAAE,KAAK,GAAG;oBACrB,KAAK,MAAM,CAAC,GAAG,CAAC,4KAAa,CAAC,EAAE,KAAK,CAAC,KAAK,KAAK;gBACpD;YACJ;YACA,yCAAyC;YACzC,KAAK,MAAM,CAAC,GAAG,CAAC,KAAK,GAAG,CAAC,SAAS,EAAE;gBAAC;gBAAG,KAAK,IAAI;aAAC;YAClD,aAAa,IAAI,CAAC,KAAK,MAAM;YAC7B,IAAI,QAAQ,aAAa,EACrB,QAAQ,aAAa,CAAC;QAC9B;IACJ;IACA,kBAAkB,GAClB,IAAI,CAAC,MACD,MAAM,IAAI,MAAM;IACpB,MAAM,aAAa,MAAM,IAAA,iLAAe,EAAC,MAAM,QAAQ;IACvD,oBAAoB,GACpB,IAAI,CAAC,WAAW,EAAE,EAAE;QAChB,MAAM,IAAI,MAAM,+BAA+B;YAAE,OAAO,WAAW,KAAK;QAAC;IAC7E;IACA,MAAM,cAAc,MAAM,qLAAM,CAAC,MAAM,CAAC,WAAW,EAAE;IACrD,MAAM,YAAY,gLAAW,CAAC,wKAAQ,EAAE;IACxC,MAAM,CAAC,aAAa,cAAc,cAAc,GAAG,MAAM,QAAQ,GAAG,CAAC;QACjE,UAAU;YACN;gBACI,KAAK,mLAAe;gBACpB,IAAI,iLAAa,CAAC,aAAa,WAAW,EAAE,CAAC,MAAM;YACvD;SACH;QACD,UAAU;YACN;gBACI,KAAK,oLAAgB;gBACrB,IAAI,kLAAc,CAAC;YACvB;SACH;QACD,UAAU;YACN;gBACI,KAAK,qLAAiB;gBACtB,IAAI,mLAAe,CAAC,MAAM;YAC9B;SACH;KACJ;IACD,+BAA+B;IAC/B,MAAM,+KAAQ,CAAC,aAAa,aAAa,WAAW,EAAE,EAAE;IACxD,sCAAsC;IACtC,MAAM,gLAAS,CAAC,cAAc,WAAW;IACzC,sCAAsC;IACtC,MAAM,iLAAU,CAAC,eAAe,MAAM,QAAQ;IAC9C,OAAO;AACX;AAOO,eAAe,aAAa,IAAI,EAAE,MAAM,EAAE,EAAE,cAAc,2KAAW,EAAE,GAAG,SAAS,GAAG,CAAC,CAAC;IAC3F,wDAAwD,GACxD,MAAM,YAAY,OAAO,SAAS,aAAa,OAAO,IAAM;IAC5D,IAAI,QAAQ,MAAM,IAAI,QAAQ,QAAQ,MAAM,KAAK,MAAM;QACnD,SAAS,IAAA,oLAAM,EAAC;IACpB;IACA,gDAAgD,GAChD,IAAI;IACJ,MAAM,cAAc,IAAI,eAAe;QACnC,MAAK,UAAU;YACX,KAAK,MAAM,KAAK,OAAQ;gBACpB,WAAW,OAAO,CAAC;YACvB;YACA,WAAW,KAAK;QACpB;IACJ;IACA,qBAAqB;IACrB,MAAM,YACD,WAAW,CAAC,IAAI,uLAAc,CAAC;QAAE,GAAG,OAAO;QAAE,WAAW;IAAS,IACjE,MAAM,CAAC,IAAI,eAAe;QAC3B,OAAO,CAAC;YACJ,MAAM;QACV;IACJ;IACA,oBAAoB,GACpB,0CAA0C;IAC1C,IAAI,CAAC,KACD,MAAM,IAAI,MAAM;IACpB,MAAM,OAAO,IAAI,KAAK,CAAC,EAAE;IACzB,MAAM,QAAQ,IAAI,WAAW,MAAM,IAAI,WAAW;IAClD,MAAM,SAAS,MAAM,qLAAM,CAAC,MAAM,CAAC;IACnC,MAAM,CAAC,WAAW,UAAU,GAAG,MAAM,QAAQ,GAAG,CAAC;QAC7C,CAAC;YACG,MAAM,OAAO,MAAM,UAAU;gBACzB;oBACI,KAAK,mLAAe;oBACpB,IAAI,iLAAa,CAAC,QAAQ,MAAM,MAAM;gBAC1C;aACH;YACD,kDAAkD;YAClD,MAAM,+KAAQ,CAAC,MAAM,QAAQ,OAAO;YACpC,MAAM,MAAM,gLAAW,CAAC,wKAAQ,EAAE;YAClC,IAAI;YACJ,IAAI,aAAa;gBACb,MAAM,kBAAkB,MAAM,YAAY,MAAM,CAAC;gBACjD,6DAA6D,GAC7D,QAAQ,gLAAW,CAAC,uKAAQ,EAAE;gBAC9B,iCAAiC;gBACjC,MAAM,SAAS,MAAM,6NAAU,CAAC,aAAa,CAAC;oBAC1C,QAAQ,KAAK,MAAM;oBACnB,UAAU,KAAK,QAAQ;oBACvB,iEAAiE;oBACjE,MAAM,KAAK,MAAM,CAAC,GAAG;oBACrB,QAAQ,KAAK,MAAM;gBACvB,GAAG,gLAAW,CAAC,uKAAQ,EAAE,SAAS,OAAO;gBACzC,IAAI,OAAO,GAAG,CAAC,KAAK,EAAE;oBAClB,MAAM,IAAI,MAAM,4DAA4D;wBAAE,OAAO,OAAO,GAAG,CAAC,KAAK;oBAAC;gBAC1G;YACJ;YACA,MAAM,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,GAAG;YACzC,QAAQ,aAAa,GAAG;gBAAE;gBAAS;gBAAO;gBAAM;gBAAO;gBAAK;YAAO;YACnE,OAAO;QACX,CAAC;QACD,CAAC;YACG,MAAM,QAAQ,+OAAe,CAAC,MAAM,CAAC;YACrC,KAAK,MAAM,CAAC,OAAO,IAAI,IAAI,IAAI,MAAM,CAAE;gBACnC,MAAM,QAAQ,CAAC,QAAQ,OAAO;YAClC;YACA,yCAAyC;YACzC,MAAM,QAAQ,CAAC,QAAQ,QAAQ;gBAAC;gBAAG,IAAI,IAAI;aAAC;YAC5C,MAAM,aAAa,MAAM,MAAM,OAAO;YACtC,oBAAoB,GACpB,IAAI,CAAC,WAAW,EAAE,EAAE;gBAChB,MAAM,IAAI,MAAM,+BAA+B;oBAC3C,OAAO,WAAW,KAAK;gBAC3B;YACJ;YACA,MAAM,cAAc,MAAM,qLAAM,CAAC,MAAM,CAAC,WAAW,EAAE;YACrD,MAAM,YAAY,gLAAW,CAAC,wKAAQ,EAAE;YACxC,MAAM,OAAO,MAAM,UAAU;gBACzB;oBACI,KAAK,mLAAe;oBACpB,IAAI,iLAAa,CAAC,aAAa,WAAW,EAAE,CAAC,MAAM;gBACvD;aACH;YACD,+BAA+B;YAC/B,MAAM,+KAAQ,CAAC,MAAM,aAAa,WAAW,EAAE,EAAE;YACjD,OAAO;QACX,CAAC;KACJ;IACD,MAAM,QAAQ,GAAG,CAAC;QACd,CAAC;YACG,MAAM,OAAO,MAAM,UAAU;gBACzB;oBACI,KAAK,oLAAgB;oBACrB,IAAI,kLAAc,CAAC;gBACvB;aACH;YACD,sCAAsC;YACtC,MAAM,gLAAS,CAAC,MAAM,WAAW;QACrC,CAAC;QACD,CAAC;YACG,MAAM,OAAO,MAAM,UAAU;gBACzB;oBACI,KAAK,qLAAiB;oBACtB,IAAI,mLAAe,CAAC,MAAM;wBAAC;qBAAU;gBACzC;aACH;YACD,sCAAsC;YACtC,MAAM,iLAAU,CAAC,MAAM,MAAM;gBAAC;aAAU,EAAE;QAC9C,CAAC;KACJ;IACD,OAAO;AACX,EACA,iCAAiC","ignoreList":[0]}}]
}